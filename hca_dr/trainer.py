"""
HCA-DR Trainer
ä¸‰é˜¶æ®µè®­ç»ƒé€»è¾‘å®ç°ï¼š
- é˜¶æ®µ1ï¼šå…¨å±€æ¨¡å‹é¢„è®­ç»ƒ
- é˜¶æ®µ2ï¼šFiLMåˆ†æ”¯è®­ç»ƒ
- é˜¶æ®µ3ï¼šç«¯åˆ°ç«¯å¾®è°ƒ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import time
from tqdm import tqdm
import json
from collections import defaultdict

from model import HCADR, HCADROutput
from losses import Stage1Loss, Stage2Loss, Stage3Loss, HCADRLoss
from config import HCADRConfig


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    
    def __init__(self, patience: int = 10, min_delta: float = 1e-4, mode: str = 'min'):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False
    
    def __call__(self, score: float) -> bool:
        if self.best_score is None:
            self.best_score = score
            return False
        
        if self.mode == 'min':
            improved = score < self.best_score - self.min_delta
        else:
            improved = score > self.best_score + self.min_delta
        
        if improved:
            self.best_score = score
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        
        return self.early_stop


class HCADRTrainer:
    """
    HCA-DRè®­ç»ƒå™¨
    
    å®ç°ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥
    """
    
    def __init__(self,
                 model: HCADR,
                 config: HCADRConfig,
                 train_loader: DataLoader,
                 val_loader: DataLoader,
                 device: str = 'cuda'):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        å‚æ•°ï¼š
            model: HCA-DRæ¨¡å‹
            config: é…ç½®å¯¹è±¡
            train_loader: è®­ç»ƒDataLoader
            val_loader: éªŒè¯DataLoader
            device: è®¡ç®—è®¾å¤‡
        """
        self.model = model.to(device)
        self.config = config
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # æŸå¤±å‡½æ•°
        self.stage1_loss = Stage1Loss(gamma=config.training.focal_gamma)
        self.stage2_loss = Stage2Loss(
            gamma=config.training.focal_gamma,
            temperature=config.training.contrast_temperature,
            lambda_contrast=config.training.lambda_contrast,
            lambda_alpha=config.training.lambda_alpha_penalty
        )
        self.stage3_loss = Stage3Loss(
            gamma=config.training.focal_gamma,
            temperature=config.training.contrast_temperature,
            lambda_contrast=config.training.stage3_lambda_contrast,
            lambda_global=config.training.stage3_lambda_global,
            lambda_alpha=config.training.stage3_lambda_alpha_penalty
        )
        
        # è®­ç»ƒå†å²
        self.history = defaultdict(list)
        self.current_stage = 0
        self.current_epoch = 0
        self.best_val_loss = float('inf')
        self.best_model_state = None
        
        # è¾“å‡ºè·¯å¾„
        self.output_dir = Path(config.data.output_dir)
        self.checkpoint_dir = self.output_dir / config.data.checkpoint_dir
        self.log_dir = self.output_dir / config.data.log_dir
        
        print(f"âœ“ Trainer initialized")
        print(f"  Device: {device}")
        print(f"  Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    def _create_optimizer(self, stage: int) -> optim.Optimizer:
        """åˆ›å»ºä¼˜åŒ–å™¨"""
        cfg = self.config.training
        
        if stage == 1:
            params = self.model.get_trainable_params(stage=1)
            lr = cfg.stage1_lr
        elif stage == 2:
            params = self.model.get_trainable_params(stage=2)
            lr = cfg.stage2_lr
        else:
            params = self.model.get_trainable_params(stage=3)
            lr = cfg.stage3_lr
        
        optimizer = optim.AdamW(
            params,
            lr=lr,
            betas=(cfg.beta1, cfg.beta2),
            eps=cfg.eps,
            weight_decay=cfg.weight_decay
        )
        
        return optimizer
    
    def _create_scheduler(self, optimizer: optim.Optimizer, stage: int, n_epochs: int):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        cfg = self.config.training
        
        if stage == 1:
            # Warmup + æ’å®š
            def warmup_fn(epoch):
                if epoch < cfg.warmup_epochs:
                    return (epoch + 1) / cfg.warmup_epochs
                return 1.0
            scheduler = LambdaLR(optimizer, warmup_fn)
        
        elif stage == 2:
            # Cosineè¡°å‡
            scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0)
        
        else:
            # æ’å®šå­¦ä¹ ç‡
            scheduler = LambdaLR(optimizer, lambda epoch: 1.0)
        
        return scheduler
    
    def train_stage1(self, n_epochs: Optional[int] = None) -> Dict:
        """
        é˜¶æ®µ1ï¼šå…¨å±€æ¨¡å‹é¢„è®­ç»ƒ
        
        ç›®æ ‡ï¼šå¤ç°DrugReflectorï¼Œå»ºç«‹å¼ºå¤§çš„å…¨å±€åŸºçº¿
        
        è®­ç»ƒï¼š
        - å…¨å±€æ‰°åŠ¨ç¼–ç å™¨
        - åˆ†ç±»å¤´
        
        å†»ç»“ï¼š
        - ä¸Šä¸‹æ–‡ç¼–ç å™¨
        - FiLMæ¨¡å—
        """
        print("\n" + "=" * 80)
        print("ğŸ“Š STAGE 1: Global Model Pre-training")
        print("=" * 80)
        
        self.current_stage = 1
        n_epochs = n_epochs or self.config.training.stage1_epochs
        
        # å†»ç»“ä¸Šä¸‹æ–‡å’ŒFiLMæ¨¡å—
        self.model.freeze_context_and_film()
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer = self._create_optimizer(stage=1)
        scheduler = self._create_scheduler(optimizer, stage=1, n_epochs=n_epochs)
        
        # æ—©åœ
        early_stopping = EarlyStopping(
            patience=self.config.training.patience,
            min_delta=self.config.training.min_delta
        )
        
        for epoch in range(n_epochs):
            self.current_epoch = epoch
            
            # è®­ç»ƒ
            train_metrics = self._train_epoch_stage1(optimizer)
            
            # éªŒè¯
            val_metrics = self._validate_stage1()
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            # è®°å½•
            self._log_epoch(epoch, n_epochs, train_metrics, val_metrics, stage=1)
            
            # ä¿å­˜æœ€ä¼˜æ¨¡å‹
            if val_metrics['val_loss'] < self.best_val_loss:
                self.best_val_loss = val_metrics['val_loss']
                self.best_model_state = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}
                self._save_checkpoint(epoch, stage=1, is_best=True)
            
            # æ—©åœæ£€æŸ¥
            if early_stopping(val_metrics['val_loss']):
                print(f"\n   Early stopping triggered at epoch {epoch+1}")
                break
        
        # æ¢å¤æœ€ä¼˜æ¨¡å‹
        if self.best_model_state is not None:
            self.model.load_state_dict(self.best_model_state)
        
        return {'stage': 1, 'final_val_loss': self.best_val_loss}
    
    def train_stage2(self, n_epochs: Optional[int] = None) -> Dict:
        """
        é˜¶æ®µ2ï¼šFiLMåˆ†æ”¯è®­ç»ƒ
        
        ç›®æ ‡ï¼šè®©FiLMå­¦ä¹ å…¨å±€æ¨¡å‹çš„æ®‹å·®ï¼ˆç»†èƒç³»ç‰¹å¼‚æ€§ä¿¡æ¯ï¼‰
        
        è®­ç»ƒï¼š
        - ä¸Šä¸‹æ–‡ç¼–ç å™¨
        - FiLMæ¨¡å—
        - åˆ†ç±»å¤´
        
        å†»ç»“ï¼š
        - å…¨å±€æ‰°åŠ¨ç¼–ç å™¨
        """
        print("\n" + "=" * 80)
        print("ğŸ“Š STAGE 2: FiLM Branch Training")
        print("=" * 80)
        
        self.current_stage = 2
        n_epochs = n_epochs or self.config.training.stage2_epochs
        
        # å†»ç»“å…¨å±€ç¼–ç å™¨ï¼Œè§£å†»ä¸Šä¸‹æ–‡å’ŒFiLM
        self.model.freeze_global_encoder()
        self.model.unfreeze_context_and_film()
        
        # é‡ç½®æœ€ä¼˜æŸå¤±
        self.best_val_loss = float('inf')
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer = self._create_optimizer(stage=2)
        scheduler = self._create_scheduler(optimizer, stage=2, n_epochs=n_epochs)
        
        # æ—©åœ
        early_stopping = EarlyStopping(
            patience=self.config.training.patience,
            min_delta=self.config.training.min_delta
        )
        
        for epoch in range(n_epochs):
            self.current_epoch = epoch
            
            # è®­ç»ƒ
            train_metrics = self._train_epoch_stage2(optimizer)
            
            # éªŒè¯
            val_metrics = self._validate_stage2()
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            # è®°å½•
            self._log_epoch(epoch, n_epochs, train_metrics, val_metrics, stage=2)
            
            # ä¿å­˜æœ€ä¼˜æ¨¡å‹
            if val_metrics['val_loss'] < self.best_val_loss:
                self.best_val_loss = val_metrics['val_loss']
                self.best_model_state = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}
                self._save_checkpoint(epoch, stage=2, is_best=True)
            
            # æ—©åœæ£€æŸ¥
            if early_stopping(val_metrics['val_loss']):
                print(f"\n   Early stopping triggered at epoch {epoch+1}")
                break
        
        # æ¢å¤æœ€ä¼˜æ¨¡å‹
        if self.best_model_state is not None:
            self.model.load_state_dict(self.best_model_state)
        
        return {'stage': 2, 'final_val_loss': self.best_val_loss}
    
    def train_stage3(self, n_epochs: Optional[int] = None) -> Dict:
        """
        é˜¶æ®µ3ï¼šç«¯åˆ°ç«¯å¾®è°ƒ
        
        ç›®æ ‡ï¼šè”åˆä¼˜åŒ–æ‰€æœ‰å‚æ•°
        
        è®­ç»ƒï¼š
        - æ‰€æœ‰å‚æ•°
        """
        print("\n" + "=" * 80)
        print("ğŸ“Š STAGE 3: End-to-End Fine-tuning")
        print("=" * 80)
        
        self.current_stage = 3
        n_epochs = n_epochs or self.config.training.stage3_epochs
        
        # è§£å†»æ‰€æœ‰å‚æ•°
        self.model.unfreeze_global_encoder()
        self.model.unfreeze_context_and_film()
        
        # é‡ç½®æœ€ä¼˜æŸå¤±
        self.best_val_loss = float('inf')
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer = self._create_optimizer(stage=3)
        scheduler = self._create_scheduler(optimizer, stage=3, n_epochs=n_epochs)
        
        # æ—©åœ
        early_stopping = EarlyStopping(
            patience=self.config.training.patience,
            min_delta=self.config.training.min_delta
        )
        
        for epoch in range(n_epochs):
            self.current_epoch = epoch
            
            # è®­ç»ƒ
            train_metrics = self._train_epoch_stage3(optimizer)
            
            # éªŒè¯
            val_metrics = self._validate_stage3()
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            # è®°å½•
            self._log_epoch(epoch, n_epochs, train_metrics, val_metrics, stage=3)
            
            # ä¿å­˜æœ€ä¼˜æ¨¡å‹
            if val_metrics['val_loss'] < self.best_val_loss:
                self.best_val_loss = val_metrics['val_loss']
                self.best_model_state = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}
                self._save_checkpoint(epoch, stage=3, is_best=True)
            
            # æ—©åœæ£€æŸ¥
            if early_stopping(val_metrics['val_loss']):
                print(f"\n   Early stopping triggered at epoch {epoch+1}")
                break
        
        # æ¢å¤æœ€ä¼˜æ¨¡å‹
        if self.best_model_state is not None:
            self.model.load_state_dict(self.best_model_state)
        
        return {'stage': 3, 'final_val_loss': self.best_val_loss}
    
    def _train_epoch_stage1(self, optimizer: optim.Optimizer) -> Dict:
        """é˜¶æ®µ1å•ä¸ªepochè®­ç»ƒ"""
        self.model.train()
        
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        
        pbar = tqdm(self.train_loader, desc=f"Stage 1 Training", leave=False)
        
        for batch in pbar:
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            x_pert = batch['x_pert'].to(self.device)
            y = batch['y'].to(self.device)
            
            # å‰å‘ä¼ æ’­ï¼ˆä»…ä½¿ç”¨å…¨å±€æ¨¡å‹ï¼‰
            optimizer.zero_grad()
            logits = self.model.forward_global_only(x_pert)
            
            # è®¡ç®—æŸå¤±
            loss, loss_dict = self.stage1_loss(logits, y)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item() * len(y)
            pred = logits.argmax(dim=1)
            total_correct += (pred == y).sum().item()
            total_samples += len(y)
            
            pbar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'acc': f"{total_correct/total_samples*100:.2f}%"
            })
        
        return {
            'train_loss': total_loss / total_samples,
            'train_acc': total_correct / total_samples
        }
    
    def _train_epoch_stage2(self, optimizer: optim.Optimizer) -> Dict:
        """é˜¶æ®µ2å•ä¸ªepochè®­ç»ƒ"""
        self.model.train()
        
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        alpha_sum = 0.0
        dropout_alpha_sum = 0.0
        dropout_count = 0
        
        pbar = tqdm(self.train_loader, desc=f"Stage 2 Training", leave=False)
        
        for batch in pbar:
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            x_pert = batch['x_pert'].to(self.device)
            x_ctx = batch['x_ctx'].to(self.device)
            y = batch['y'].to(self.device)
            cell_ids = batch['cell_id'].to(self.device)
            is_ctx_dropout = batch['is_ctx_dropout'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            output = self.model(x_pert, x_ctx)
            
            # è®¡ç®—æŸå¤±
            loss, loss_dict = self.stage2_loss(
                output.logits, output.h_ctx, output.alpha,
                y, cell_ids, is_ctx_dropout
            )
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item() * len(y)
            pred = output.logits.argmax(dim=1)
            total_correct += (pred == y).sum().item()
            total_samples += len(y)
            
            # Alphaç»Ÿè®¡
            alpha_sum += output.alpha.sum().item()
            dropout_mask = is_ctx_dropout > 0.5
            if dropout_mask.sum() > 0:
                dropout_alpha_sum += output.alpha[dropout_mask].sum().item()
                dropout_count += dropout_mask.sum().item()
            
            pbar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'Î±': f"{output.alpha.mean().item():.3f}"
            })
        
        return {
            'train_loss': total_loss / total_samples,
            'train_acc': total_correct / total_samples,
            'mean_alpha': alpha_sum / total_samples,
            'dropout_alpha': dropout_alpha_sum / max(dropout_count, 1)
        }
    
    def _train_epoch_stage3(self, optimizer: optim.Optimizer) -> Dict:
        """é˜¶æ®µ3å•ä¸ªepochè®­ç»ƒ"""
        self.model.train()
        
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        alpha_sum = 0.0
        
        pbar = tqdm(self.train_loader, desc=f"Stage 3 Training", leave=False)
        
        for batch in pbar:
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            x_pert = batch['x_pert'].to(self.device)
            x_ctx = batch['x_ctx'].to(self.device)
            y = batch['y'].to(self.device)
            cell_ids = batch['cell_id'].to(self.device)
            is_ctx_dropout = batch['is_ctx_dropout'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            output = self.model(x_pert, x_ctx)
            
            # è®¡ç®—æŸå¤±
            loss, loss_dict = self.stage3_loss(
                output.logits, output.logits_global, output.h_ctx, output.alpha,
                y, cell_ids, is_ctx_dropout
            )
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item() * len(y)
            pred = output.logits.argmax(dim=1)
            total_correct += (pred == y).sum().item()
            total_samples += len(y)
            alpha_sum += output.alpha.sum().item()
            
            pbar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'acc': f"{total_correct/total_samples*100:.2f}%"
            })
        
        return {
            'train_loss': total_loss / total_samples,
            'train_acc': total_correct / total_samples,
            'mean_alpha': alpha_sum / total_samples
        }
    
    @torch.no_grad()
    def _validate_stage1(self) -> Dict:
        """é˜¶æ®µ1éªŒè¯"""
        self.model.eval()
        
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        
        for batch in self.val_loader:
            x_pert = batch['x_pert'].to(self.device)
            y = batch['y'].to(self.device)
            
            logits = self.model.forward_global_only(x_pert)
            loss, _ = self.stage1_loss(logits, y)
            
            total_loss += loss.item() * len(y)
            pred = logits.argmax(dim=1)
            total_correct += (pred == y).sum().item()
            total_samples += len(y)
        
        return {
            'val_loss': total_loss / total_samples,
            'val_acc': total_correct / total_samples
        }
    
    @torch.no_grad()
    def _validate_stage2(self) -> Dict:
        """é˜¶æ®µ2éªŒè¯"""
        self.model.eval()
        
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        alpha_sum = 0.0
        
        for batch in self.val_loader:
            x_pert = batch['x_pert'].to(self.device)
            x_ctx = batch['x_ctx'].to(self.device)
            y = batch['y'].to(self.device)
            cell_ids = batch['cell_id'].to(self.device)
            is_ctx_dropout = batch['is_ctx_dropout'].to(self.device)
            
            output = self.model(x_pert, x_ctx)
            loss, _ = self.stage2_loss(
                output.logits, output.h_ctx, output.alpha,
                y, cell_ids, is_ctx_dropout
            )
            
            total_loss += loss.item() * len(y)
            pred = output.logits.argmax(dim=1)
            total_correct += (pred == y).sum().item()
            total_samples += len(y)
            alpha_sum += output.alpha.sum().item()
        
        return {
            'val_loss': total_loss / total_samples,
            'val_acc': total_correct / total_samples,
            'mean_alpha': alpha_sum / total_samples
        }
    
    @torch.no_grad()
    def _validate_stage3(self) -> Dict:
        """é˜¶æ®µ3éªŒè¯"""
        self.model.eval()
        
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        alpha_sum = 0.0
        
        for batch in self.val_loader:
            x_pert = batch['x_pert'].to(self.device)
            x_ctx = batch['x_ctx'].to(self.device)
            y = batch['y'].to(self.device)
            cell_ids = batch['cell_id'].to(self.device)
            is_ctx_dropout = batch['is_ctx_dropout'].to(self.device)
            
            output = self.model(x_pert, x_ctx)
            loss, _ = self.stage3_loss(
                output.logits, output.logits_global, output.h_ctx, output.alpha,
                y, cell_ids, is_ctx_dropout
            )
            
            total_loss += loss.item() * len(y)
            pred = output.logits.argmax(dim=1)
            total_correct += (pred == y).sum().item()
            total_samples += len(y)
            alpha_sum += output.alpha.sum().item()
        
        return {
            'val_loss': total_loss / total_samples,
            'val_acc': total_correct / total_samples,
            'mean_alpha': alpha_sum / total_samples
        }
    
    def _log_epoch(self, epoch: int, n_epochs: int, 
                   train_metrics: Dict, val_metrics: Dict, stage: int):
        """è®°å½•å¹¶æ‰“å°epochç»“æœ"""
        # ä¿å­˜åˆ°å†å²
        for key, value in train_metrics.items():
            self.history[f'stage{stage}_{key}'].append(value)
        for key, value in val_metrics.items():
            self.history[f'stage{stage}_{key}'].append(value)
        
        # æ‰“å°
        print(f"\n   Epoch {epoch+1}/{n_epochs}")
        print(f"   Train Loss: {train_metrics['train_loss']:.4f}, Acc: {train_metrics['train_acc']*100:.2f}%")
        print(f"   Val Loss: {val_metrics['val_loss']:.4f}, Acc: {val_metrics['val_acc']*100:.2f}%")
        
        if 'mean_alpha' in train_metrics:
            print(f"   Mean Alpha (train): {train_metrics['mean_alpha']:.4f}")
        if 'mean_alpha' in val_metrics:
            print(f"   Mean Alpha (val): {val_metrics['mean_alpha']:.4f}")
        if 'dropout_alpha' in train_metrics:
            print(f"   Dropout Alpha: {train_metrics['dropout_alpha']:.4f}")
    
    def _save_checkpoint(self, epoch: int, stage: int, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'stage': stage,
            'model_state_dict': self.model.state_dict(),
            'config': self.config,
            'history': dict(self.history),
            'best_val_loss': self.best_val_loss
        }
        
        # ä¿å­˜æœ€æ–°
        path = self.checkpoint_dir / f'stage{stage}_latest.pt'
        torch.save(checkpoint, path)
        
        # ä¿å­˜æœ€ä¼˜
        if is_best:
            path = self.checkpoint_dir / f'stage{stage}_best.pt'
            torch.save(checkpoint, path)
            print(f"   âœ“ Saved best model (val_loss: {self.best_val_loss:.4f})")
    
    def train_all_stages(self) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´çš„ä¸‰é˜¶æ®µè®­ç»ƒ
        """
        print("\n" + "=" * 80)
        print("ğŸš€ Starting HCA-DR Three-Stage Training")
        print("=" * 80)
        
        start_time = time.time()
        
        # é˜¶æ®µ1
        result1 = self.train_stage1()
        
        # é˜¶æ®µ2
        result2 = self.train_stage2()
        
        # é˜¶æ®µ3
        result3 = self.train_stage3()
        
        total_time = time.time() - start_time
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_path = self.checkpoint_dir / 'final_model.pt'
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'config': self.config,
            'history': dict(self.history),
            'training_time': total_time
        }, final_path)
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = self.log_dir / 'training_history.json'
        with open(history_path, 'w') as f:
            # è½¬æ¢numpyç±»å‹ä¸ºpythonç±»å‹
            history_dict = {}
            for k, v in self.history.items():
                history_dict[k] = [float(x) if isinstance(x, (np.floating, float)) else x for x in v]
            json.dump(history_dict, f, indent=2)
        
        print("\n" + "=" * 80)
        print("âœ… Training Complete!")
        print("=" * 80)
        print(f"   Total time: {total_time/3600:.2f} hours")
        print(f"   Final model saved to: {final_path}")
        print(f"   Training history saved to: {history_path}")
        
        return {
            'stage1': result1,
            'stage2': result2,
            'stage3': result3,
            'total_time': total_time
        }
    
    def load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.history = defaultdict(list, checkpoint.get('history', {}))
        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))
        print(f"âœ“ Loaded checkpoint from: {checkpoint_path}")


if __name__ == "__main__":
    print("HCA-DR Trainer module loaded successfully")