{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DrugReflector æ¨ç†ç¤ºä¾‹\n",
    "å±•ç¤ºå¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡ŒåŒ–åˆç‰©é¢„æµ‹\n",
    "\n",
    "ä½¿ç”¨æ–¹æ³•ï¼š\n",
    "    python inference_example.py --model-dir ./trained_models --query-file query.npy\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import List, Dict\n",
    "from drugreflector_training import (\n",
    "    DrugReflectorModel,\n",
    "    DrugReflectorEvaluator,\n",
    "    clip_and_normalize_signature\n",
    ")\n",
    "\n",
    "\n",
    "def load_ensemble_models(model_dir: Path, device='cuda') -> List[torch.nn.Module]:\n",
    "    \"\"\"\n",
    "    åŠ è½½ensembleæ¨¡å‹\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_dir: Path\n",
    "        æ¨¡å‹ç›®å½•\n",
    "    device: str\n",
    "        è®¡ç®—è®¾å¤‡\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    List[torch.nn.Module]: 3ä¸ªæ¨¡å‹\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ“‚ Loading ensemble models from {model_dir}...\")\n",
    "    \n",
    "    models = []\n",
    "    for fold_id in range(3):\n",
    "        model_path = model_dir / f\"model_fold{fold_id}.pt\"\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "        \n",
    "        # åŠ è½½æ£€æŸ¥ç‚¹\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        config = checkpoint['config']\n",
    "        \n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        model = DrugReflectorModel(\n",
    "            input_size=config['input_size'],\n",
    "            output_size=config['output_size'],\n",
    "            dropout_rate=config['dropout_rate'],\n",
    "            batch_norm_momentum=config['batch_norm_momentum']\n",
    "        )\n",
    "        \n",
    "        # åŠ è½½æƒé‡\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        models.append(model)\n",
    "        print(f\"  âœ“ Loaded model_fold{fold_id}.pt\")\n",
    "    \n",
    "    print(f\"âœ“ Ensemble loaded successfully\")\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict_top_compounds(\n",
    "    evaluator: DrugReflectorEvaluator,\n",
    "    query_signature: np.ndarray,\n",
    "    compound_names: List[str],\n",
    "    top_k: int = 100\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    é¢„æµ‹top-kåŒ–åˆç‰©\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    evaluator: DrugReflectorEvaluator\n",
    "        æ¨¡å‹è¯„ä¼°å™¨\n",
    "    query_signature: np.ndarray\n",
    "        æŸ¥è¯¢signature (1, 978)\n",
    "    compound_names: List[str]\n",
    "        åŒ–åˆç‰©åç§°åˆ—è¡¨\n",
    "    top_k: int\n",
    "        è¿”å›top-ké¢„æµ‹\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame: Top-ké¢„æµ‹ç»“æœ\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ” Predicting top {top_k} compounds...\")\n",
    "    \n",
    "    # é¢„å¤„ç†\n",
    "    query_processed = clip_and_normalize_signature(query_signature)\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    scores = evaluator.predict_ensemble(query_processed)\n",
    "    probs = torch.softmax(torch.FloatTensor(scores), dim=1).numpy()[0]\n",
    "    \n",
    "    # æ’åº\n",
    "    top_indices = np.argsort(-probs)[:top_k]\n",
    "    top_probs = probs[top_indices]\n",
    "    \n",
    "    # åˆ›å»ºç»“æœDataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'rank': range(1, top_k + 1),\n",
    "        'compound_id': [compound_names[idx] for idx in top_indices],\n",
    "        'probability': top_probs,\n",
    "        'score': scores[0, top_indices]\n",
    "    })\n",
    "    \n",
    "    print(f\"âœ“ Prediction complete\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def create_example_query(n_genes=978, seed=42) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    åˆ›å»ºç¤ºä¾‹æŸ¥è¯¢signature\n",
    "    \n",
    "    åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™åº”è¯¥æ˜¯ä»scRNA-seqæ•°æ®è®¡ç®—çš„v-score\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_genes: int\n",
    "        åŸºå› æ•°é‡\n",
    "    seed: int\n",
    "        éšæœºç§å­\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray: ç¤ºä¾‹signature (1, n_genes)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # æ¨¡æ‹Ÿä¸€ä¸ªå·®å¼‚è¡¨è¾¾signature\n",
    "    # å¤§éƒ¨åˆ†åŸºå› æ¥è¿‘0ï¼Œå°‘æ•°åŸºå› é«˜åº¦ä¸Šè°ƒæˆ–ä¸‹è°ƒ\n",
    "    signature = np.random.randn(1, n_genes) * 0.5\n",
    "    \n",
    "    # æ·»åŠ ä¸€äº›å¼ºå·®å¼‚è¡¨è¾¾åŸºå› \n",
    "    n_de_genes = 50\n",
    "    de_indices = np.random.choice(n_genes, n_de_genes, replace=False)\n",
    "    signature[0, de_indices[:25]] = np.random.uniform(1.5, 3.0, 25)  # ä¸Šè°ƒ\n",
    "    signature[0, de_indices[25:]] = np.random.uniform(-3.0, -1.5, 25)  # ä¸‹è°ƒ\n",
    "    \n",
    "    return signature\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='DrugReflector Inference Example')\n",
    "    parser.add_argument(\n",
    "        '--model-dir',\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help='Directory containing trained models'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--query-file',\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help='Path to query signature file (.npy)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--data-file',\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help='Path to training data (for compound names)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--top-k',\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help='Number of top predictions to return'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output',\n",
    "        type=str,\n",
    "        default='predictions.csv',\n",
    "        help='Output file for predictions'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--device',\n",
    "        type=str,\n",
    "        default='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        help='Device to use (cuda/cpu)'\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ§¬ DrugReflector Inference Example\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # åŠ è½½æ¨¡å‹\n",
    "    model_dir = Path(args.model_dir)\n",
    "    models = load_ensemble_models(model_dir, args.device)\n",
    "    evaluator = DrugReflectorEvaluator(models, args.device)\n",
    "    \n",
    "    # åŠ è½½åŒ–åˆç‰©åç§°\n",
    "    if args.data_file:\n",
    "        print(f\"\\nğŸ“‚ Loading compound names from {args.data_file}...\")\n",
    "        with open(args.data_file, 'rb') as f:\n",
    "            training_data = pickle.load(f)\n",
    "        compound_names = training_data['compound_names']\n",
    "    else:\n",
    "        # å°è¯•ä»æ¨¡å‹ç›®å½•åŠ è½½\n",
    "        data_file = model_dir.parent / \"processed_data\" / \"training_data_paper_compliant.pkl\"\n",
    "        if data_file.exists():\n",
    "            print(f\"\\nğŸ“‚ Loading compound names from {data_file}...\")\n",
    "            with open(data_file, 'rb') as f:\n",
    "                training_data = pickle.load(f)\n",
    "            compound_names = training_data['compound_names']\n",
    "        else:\n",
    "            # ä½¿ç”¨é»˜è®¤åç§°\n",
    "            print(f\"\\nâš ï¸  Compound names not found, using default IDs\")\n",
    "            n_compounds = len(models[0].fc3.weight)\n",
    "            compound_names = [f\"COMPOUND_{i:05d}\" for i in range(n_compounds)]\n",
    "    \n",
    "    print(f\"âœ“ Loaded {len(compound_names):,} compound names\")\n",
    "    \n",
    "    # åŠ è½½æˆ–åˆ›å»ºæŸ¥è¯¢\n",
    "    if args.query_file:\n",
    "        print(f\"\\nğŸ“‚ Loading query signature from {args.query_file}...\")\n",
    "        query_signature = np.load(args.query_file)\n",
    "        \n",
    "        if query_signature.ndim == 1:\n",
    "            query_signature = query_signature[np.newaxis, :]\n",
    "        \n",
    "        print(f\"âœ“ Query shape: {query_signature.shape}\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  No query file provided, creating example query...\")\n",
    "        query_signature = create_example_query()\n",
    "        print(f\"âœ“ Example query created (shape: {query_signature.shape})\")\n",
    "        print(f\"\\nğŸ’¡ In real use, query should be v-score from scRNA-seq:\")\n",
    "        print(f\"   v-score(state1 â†’ state2) = (mean_log(state2) - mean_log(state1)) / \")\n",
    "        print(f\"                               sqrt(var_log(state1) + var_log(state2))\")\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    results = predict_top_compounds(\n",
    "        evaluator,\n",
    "        query_signature,\n",
    "        compound_names,\n",
    "        args.top_k\n",
    "    )\n",
    "    \n",
    "    # æ˜¾ç¤ºç»“æœ\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ¯ TOP {args.top_k} PREDICTIONS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(results.head(20).to_string(index=False))\n",
    "    \n",
    "    if len(results) > 20:\n",
    "        print(f\"\\n... (showing top 20 of {len(results)} predictions)\")\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    output_file = Path(args.output)\n",
    "    results.to_csv(output_file, index=False)\n",
    "    print(f\"\\nğŸ’¾ Full predictions saved to: {output_file}\")\n",
    "    \n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"\\nğŸ“Š Prediction Statistics:\")\n",
    "    print(f\"   Mean probability: {results['probability'].mean():.6f}\")\n",
    "    print(f\"   Max probability: {results['probability'].max():.6f}\")\n",
    "    print(f\"   Min probability: {results['probability'].min():.6f}\")\n",
    "    print(f\"   Probability range: {results['probability'].max() - results['probability'].min():.6f}\")\n",
    "    \n",
    "    # æ¦‚ç‡åˆ†å¸ƒ\n",
    "    print(f\"\\nğŸ“ˆ Probability Distribution:\")\n",
    "    print(f\"   >0.01: {(results['probability'] > 0.01).sum()} compounds\")\n",
    "    print(f\"   >0.001: {(results['probability'] > 0.001).sum()} compounds\")\n",
    "    print(f\"   >0.0001: {(results['probability'] > 0.0001).sum()} compounds\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"âœ… Inference Complete!\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "\n",
    "def batch_inference_example():\n",
    "    \"\"\"æ‰¹é‡æ¨ç†ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“¦ Batch Inference Example\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # å‡è®¾æœ‰å¤šä¸ªæŸ¥è¯¢\n",
    "    n_queries = 10\n",
    "    queries = create_example_query(n_genes=978, seed=42)\n",
    "    queries = np.repeat(queries, n_queries, axis=0)\n",
    "    \n",
    "    print(f\"  Processing {n_queries} queries...\")\n",
    "    print(f\"  Query batch shape: {queries.shape}\")\n",
    "    \n",
    "    # è¿™é‡Œå¯ä»¥æ·»åŠ æ‰¹é‡é¢„æµ‹ä»£ç \n",
    "    # ...\n",
    "    \n",
    "    print(f\"  âœ“ Batch inference complete\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    # å–æ¶ˆæ³¨é‡Šä»¥è¿è¡Œæ‰¹é‡æ¨ç†ç¤ºä¾‹\n",
    "    # batch_inference_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01842490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DrugReflector åŸºåº§æ¨¡å‹è®­ç»ƒ - å®Œæ•´æŒ‡å—\n",
    "\n",
    "åŸºäº **Science 2025** è®ºæ–‡çš„DrugReflectoråŸºåº§æ¨¡å‹è®­ç»ƒå®ç°\n",
    "\n",
    "> DeMeo et al. (2025). Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes. *Science*. DOI: 10.1126/science.adi8577\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ æ–‡ä»¶æ¸…å•\n",
    "\n",
    "```\n",
    "drugreflector/\n",
    "â”œâ”€â”€ drugreflector_preprocessing_optimized.py  # æ•°æ®é¢„å¤„ç†ï¼ˆä¸¥æ ¼éµå¾ªSIï¼‰\n",
    "â”œâ”€â”€ drugreflector_training.py                 # æ¨¡å‹è®­ç»ƒæ ¸å¿ƒä»£ç \n",
    "â”œâ”€â”€ training_config.py                        # è®­ç»ƒé…ç½®æ–‡ä»¶\n",
    "â”œâ”€â”€ quick_train.py                            # å¿«é€Ÿå¯åŠ¨è„šæœ¬ â­\n",
    "â”œâ”€â”€ inference_example.py                      # æ¨ç†ç¤ºä¾‹\n",
    "â”œâ”€â”€ TRAINING_GUIDE.md                         # è¯¦ç»†è®­ç»ƒæŒ‡å—\n",
    "â””â”€â”€ README.md                                 # æœ¬æ–‡ä»¶\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ å¿«é€Ÿå¼€å§‹\n",
    "\n",
    "### 1. ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "```bash\n",
    "# å®‰è£…ä¾èµ–\n",
    "pip install torch torchvision numpy pandas scipy scikit-learn h5py tqdm matplotlib\n",
    "\n",
    "# æ£€æŸ¥GPUï¼ˆæ¨èï¼‰\n",
    "python -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\n",
    "```\n",
    "\n",
    "### 2. æ•°æ®é¢„å¤„ç†\n",
    "\n",
    "```bash\n",
    "# è¿è¡Œé¢„å¤„ç†è„šæœ¬\n",
    "python drugreflector_preprocessing_optimized.py\n",
    "\n",
    "# é¢„æœŸè¾“å‡ºï¼štraining_data_paper_compliant.pkl\n",
    "# 425,242 æ ·æœ¬ Ã— 978 åŸºå›  â†’ 9,597 åŒ–åˆç‰©\n",
    "```\n",
    "\n",
    "### 3. è®­ç»ƒæ¨¡å‹\n",
    "\n",
    "**ä½¿ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰ï¼š**\n",
    "\n",
    "```bash\n",
    "# é»˜è®¤é…ç½®ï¼ˆä¸è®ºæ–‡ä¸€è‡´ï¼‰\n",
    "python quick_train.py\n",
    "\n",
    "# å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆ10 epochsï¼‰\n",
    "python quick_train.py --mode fast\n",
    "\n",
    "# é«˜ç²¾åº¦æ¨¡å¼ï¼ˆ100 epochsï¼‰\n",
    "python quick_train.py --mode high_precision\n",
    "\n",
    "# ä½å†…å­˜æ¨¡å¼ï¼ˆGPU <8GBï¼‰\n",
    "python quick_train.py --mode low_memory\n",
    "```\n",
    "\n",
    "**æˆ–è€…ç›´æ¥è¿è¡Œè®­ç»ƒè„šæœ¬ï¼š**\n",
    "\n",
    "```bash\n",
    "python drugreflector_training.py\n",
    "```\n",
    "\n",
    "### 4. ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "\n",
    "```bash\n",
    "# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹\n",
    "python inference_example.py --model-dir ./trained_models --top-k 100\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š è®­ç»ƒæµç¨‹è¯¦è§£\n",
    "\n",
    "### å®Œæ•´æµç¨‹\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    1. æ•°æ®é¢„å¤„ç†                                  â”‚\n",
    "â”‚  LINCS Level 4 â†’ 6æ­¥è´¨æ§è¿‡æ»¤ â†’ 425Kæ ·æœ¬ Ã— 978åŸºå›                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    2. æ•°æ®æ ‡å‡†åŒ–                                  â”‚\n",
    "â”‚  Clip to [-2, 2] â†’ Normalize std=1                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    3. 3-Fold åˆ’åˆ†                                â”‚\n",
    "â”‚  Fold 0: Train(1,2) Val(0)                                      â”‚\n",
    "â”‚  Fold 1: Train(0,2) Val(1)                                      â”‚\n",
    "â”‚  Fold 2: Train(0,1) Val(2)                                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    4. æ¨¡å‹è®­ç»ƒï¼ˆæ¯ä¸ªfoldï¼‰                         â”‚\n",
    "â”‚  50 epochs Ã— Focal Loss Ã— Cosine Annealing                      â”‚\n",
    "â”‚  Dropout(0.64) + BatchNorm + Early Stop                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    5. Ensembleé¢„æµ‹                               â”‚\n",
    "â”‚  å¹³å‡3ä¸ªæ¨¡å‹çš„logits â†’ Softmax â†’ æ’åº                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ—ï¸ æ¨¡å‹æ¶æ„\n",
    "\n",
    "```\n",
    "Input (978 landmark genes)\n",
    "    â†“\n",
    "Linear(978 â†’ 1,024) + BatchNorm + ReLU + Dropout(0.64)\n",
    "    â†“\n",
    "Linear(1,024 â†’ 2,048) + BatchNorm + ReLU + Dropout(0.64)\n",
    "    â†“\n",
    "Linear(2,048 â†’ 9,597)\n",
    "    â†“\n",
    "Output (9,597 compounds)\n",
    "\n",
    "æ€»å‚æ•°: ~22.7M\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ å…³é”®è¶…å‚æ•°\n",
    "\n",
    "| å‚æ•° | å€¼ | æ¥æº | è¯´æ˜ |\n",
    "|------|-----|------|------|\n",
    "| **Dropout** | 0.64 | SI Table S5 | é˜²æ­¢è¿‡æ‹Ÿåˆ |\n",
    "| **Initial LR** | 0.0139 | SI Table S5 | åˆå§‹å­¦ä¹ ç‡ |\n",
    "| **Min LR** | 0.00001 | SI Page 3 | æœ€å°å­¦ä¹ ç‡ |\n",
    "| **Weight Decay** | 1e-5 | SI Table S5 | L2æ­£åˆ™åŒ– |\n",
    "| **T_0** | 20 | SI Table S5 | Warm restartå‘¨æœŸ |\n",
    "| **Focal Î³** | 2.0 | SI Page 3 | Focal losså‚æ•° |\n",
    "| **Batch Size** | 256 | - | æ ¹æ®GPUè°ƒæ•´ |\n",
    "| **Epochs** | 50 | SI Page 3 | æ€»è®­ç»ƒè½®æ•° |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ é¢„æœŸæ€§èƒ½\n",
    "\n",
    "æ ¹æ®è®ºæ–‡SIç¬¬24é¡µçš„ç»“æœï¼š\n",
    "\n",
    "| æ•°æ®é›† | Top 1% Recall | Top-10 Accuracy |\n",
    "|--------|---------------|-----------------|\n",
    "| **CMap Touchstone** | 0.46-0.50 | 0.35-0.40 |\n",
    "| **sciPlex3** | 0.30-0.35 | 0.20-0.25 |\n",
    "| **Internal** | 0.60-0.65 | 0.45-0.50 |\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œæ‚¨çš„æ¨¡å‹åº”è¯¥åœ¨ç›¸ä¼¼èŒƒå›´å†…ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» ç¡¬ä»¶è¦æ±‚\n",
    "\n",
    "### æ¨èé…ç½®\n",
    "- **GPU**: NVIDIA RTX 3090 / A100 (24GB VRAM)\n",
    "- **RAM**: 32GB+\n",
    "- **å­˜å‚¨**: 50GB+ å¯ç”¨ç©ºé—´\n",
    "- **è®­ç»ƒæ—¶é—´**: ~18-24å°æ—¶ï¼ˆ3ä¸ªæ¨¡å‹ï¼‰\n",
    "\n",
    "### æœ€ä½é…ç½®\n",
    "- **GPU**: NVIDIA RTX 2060 (8GB VRAM)\n",
    "- **RAM**: 16GB\n",
    "- **å­˜å‚¨**: 30GB\n",
    "- **è®­ç»ƒæ—¶é—´**: ~36-48å°æ—¶\n",
    "\n",
    "### CPUè®­ç»ƒ\n",
    "- å¯è¡Œä½†**éå¸¸æ…¢**ï¼ˆ~7-10å¤©ï¼‰\n",
    "- ä¸æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– è¯¦ç»†æ–‡æ¡£\n",
    "\n",
    "### 1. [TRAINING_GUIDE.md](TRAINING_GUIDE.md)\n",
    "å®Œæ•´çš„è®­ç»ƒæŒ‡å—ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- å…³é”®æŠ€æœ¯ç»†èŠ‚ï¼ˆFocal Lossã€å­¦ä¹ ç‡è°ƒåº¦ç­‰ï¼‰\n",
    "- è¶…å‚æ•°è°ƒä¼˜å»ºè®®\n",
    "- æ€§èƒ½ä¼˜åŒ–æŠ€å·§\n",
    "- å¸¸è§é—®é¢˜è§£ç­”\n",
    "\n",
    "### 2. [MODIFICATIONS_EXPLAINED.md](MODIFICATIONS_EXPLAINED.md)\n",
    "ä»£ç ä¿®æ”¹è¯´æ˜ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- ä¸åŸå§‹ä»£ç çš„å¯¹æ¯”\n",
    "- ç¬¦åˆè®ºæ–‡çš„ä¿®æ­£\n",
    "- æ€§èƒ½ä¼˜åŒ–è¯¦è§£\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ é…ç½®æ¨¡å¼\n",
    "\n",
    "### Defaultï¼ˆé»˜è®¤ï¼‰\n",
    "ä¸è®ºæ–‡å®Œå…¨ä¸€è‡´çš„é…ç½®\n",
    "```python\n",
    "python quick_train.py --mode default\n",
    "```\n",
    "\n",
    "### Fastï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰\n",
    "ç”¨äºå¿«é€ŸéªŒè¯æµç¨‹ï¼ˆ10 epochsï¼‰\n",
    "```python\n",
    "python quick_train.py --mode fast\n",
    "```\n",
    "\n",
    "### High Precisionï¼ˆé«˜ç²¾åº¦ï¼‰\n",
    "è¿½æ±‚æœ€ä½³æ€§èƒ½ï¼ˆ100 epochsï¼‰\n",
    "```python\n",
    "python quick_train.py --mode high_precision\n",
    "```\n",
    "\n",
    "### Low Memoryï¼ˆä½å†…å­˜ï¼‰\n",
    "é€‚åˆGPUå†…å­˜<8GBçš„æƒ…å†µ\n",
    "```python\n",
    "python quick_train.py --mode low_memory\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š è®­ç»ƒè¾“å‡º\n",
    "\n",
    "è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š\n",
    "\n",
    "```\n",
    "trained_models/\n",
    "â”œâ”€â”€ model_fold0.pt              # Fold 0 æ¨¡å‹ + å†å²\n",
    "â”œâ”€â”€ model_fold1.pt              # Fold 1 æ¨¡å‹ + å†å²\n",
    "â”œâ”€â”€ model_fold2.pt              # Fold 2 æ¨¡å‹ + å†å²\n",
    "â”œâ”€â”€ ensemble_history.pkl        # 3ä¸ªæ¨¡å‹çš„è®­ç»ƒå†å²\n",
    "â”œâ”€â”€ training_history.png        # è®­ç»ƒæ›²çº¿å¯è§†åŒ–\n",
    "â”œâ”€â”€ fold0_results.pkl           # Fold 0 è¯„ä¼°ç»“æœ\n",
    "â”œâ”€â”€ fold1_results.pkl           # Fold 1 è¯„ä¼°ç»“æœ\n",
    "â””â”€â”€ fold2_results.pkl           # Fold 2 è¯„ä¼°ç»“æœ\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹\n",
    "\n",
    "### åŸºç¡€æ¨ç†\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import numpy as np\n",
    "from drugreflector_training import (\n",
    "    DrugReflectorModel,\n",
    "    DrugReflectorEvaluator,\n",
    "    clip_and_normalize_signature\n",
    ")\n",
    "\n",
    "# 1. åŠ è½½æ¨¡å‹\n",
    "models = []\n",
    "for fold_id in range(3):\n",
    "    checkpoint = torch.load(f'model_fold{fold_id}.pt')\n",
    "    model = DrugReflectorModel(input_size=978, output_size=9597)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "# 2. åˆ›å»ºè¯„ä¼°å™¨\n",
    "evaluator = DrugReflectorEvaluator(models, device='cuda')\n",
    "\n",
    "# 3. å‡†å¤‡æŸ¥è¯¢signatureï¼ˆä»scRNA-seqè®¡ç®—çš„v-scoreï¼‰\n",
    "query = np.random.randn(1, 978)  # ç¤ºä¾‹\n",
    "\n",
    "# 4. é¢„æµ‹\n",
    "scores = evaluator.predict_ensemble(query)\n",
    "probs = torch.softmax(torch.FloatTensor(scores), dim=1).numpy()\n",
    "\n",
    "# 5. è·å–top-100é¢„æµ‹\n",
    "top_100_indices = np.argsort(-probs[0])[:100]\n",
    "```\n",
    "\n",
    "### ä½¿ç”¨æ¨ç†è„šæœ¬\n",
    "\n",
    "```bash\n",
    "# é¢„æµ‹top-100åŒ–åˆç‰©\n",
    "python inference_example.py \\\n",
    "    --model-dir ./trained_models \\\n",
    "    --query-file my_signature.npy \\\n",
    "    --top-k 100 \\\n",
    "    --output predictions.csv\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ æ•…éšœæ’æŸ¥\n",
    "\n",
    "### å¸¸è§é”™è¯¯\n",
    "\n",
    "#### 1. CUDA Out of Memory\n",
    "```bash\n",
    "# è§£å†³æ–¹æ¡ˆï¼šå‡å°batch size\n",
    "python quick_train.py --mode low_memory\n",
    "```\n",
    "\n",
    "#### 2. æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°\n",
    "```bash\n",
    "# ç¡®ä¿å…ˆè¿è¡Œé¢„å¤„ç†\n",
    "python drugreflector_preprocessing_optimized.py\n",
    "```\n",
    "\n",
    "#### 3. è®­ç»ƒé€Ÿåº¦æ…¢\n",
    "```bash\n",
    "# å¯ç”¨æ··åˆç²¾åº¦ï¼ˆéœ€PyTorch â‰¥1.6ï¼‰\n",
    "# ä»£ç ä¸­å·²è‡ªåŠ¨å¯ç”¨ï¼ˆå¦‚æœGPUæ”¯æŒï¼‰\n",
    "```\n",
    "\n",
    "#### 4. æ¨¡å‹ä¸æ”¶æ•›\n",
    "- æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦åˆé€‚\n",
    "- ç¡®è®¤æ•°æ®é¢„å¤„ç†æ­£ç¡®\n",
    "- æŸ¥çœ‹è®­ç»ƒæ›²çº¿æ‰¾å¼‚å¸¸\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ å¼•ç”¨\n",
    "\n",
    "å¦‚æœä½¿ç”¨æœ¬ä»£ç ï¼Œè¯·å¼•ç”¨åŸè®ºæ–‡ï¼š\n",
    "\n",
    "```bibtex\n",
    "@article{demeo2025drugreflector,\n",
    "  title={Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes},\n",
    "  author={DeMeo, Benjamin and others},\n",
    "  journal={Science},\n",
    "  year={2025},\n",
    "  doi={10.1126/science.adi8577}\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤ è´¡çŒ®\n",
    "\n",
    "æ¬¢è¿è´¡çŒ®æ”¹è¿›ï¼š\n",
    "- æ€§èƒ½ä¼˜åŒ–\n",
    "- Bugä¿®å¤\n",
    "- æ–‡æ¡£æ”¹è¿›\n",
    "- æ–°åŠŸèƒ½æ·»åŠ \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“§ æ”¯æŒ\n",
    "\n",
    "é‡åˆ°é—®é¢˜ï¼Ÿ\n",
    "1. æŸ¥çœ‹ [TRAINING_GUIDE.md](TRAINING_GUIDE.md) çš„å¸¸è§é—®é¢˜éƒ¨åˆ†\n",
    "2. æ£€æŸ¥é”™è¯¯æ—¥å¿—\n",
    "3. ç¡®è®¤ç¯å¢ƒé…ç½®æ­£ç¡®\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“œ è®¸å¯\n",
    "\n",
    "æœ¬ä»£ç ä»…ä¾›ç ”ç©¶ä½¿ç”¨ï¼Œéµå¾ªåŸè®ºæ–‡çš„ä½¿ç”¨æ¡æ¬¾ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ è‡´è°¢\n",
    "\n",
    "æ„Ÿè°¢DrugReflectorå›¢é˜Ÿå‘å¸ƒè¯¦ç»†çš„è¡¥å……ææ–™ï¼Œä½¿å¾—å‡†ç¡®å¤ç°æˆä¸ºå¯èƒ½ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š ç›¸å…³èµ„æº\n",
    "\n",
    "- **è®ºæ–‡**: https://doi.org/10.1126/science.adi8577\n",
    "- **LINCSæ•°æ®**: https://lincsportal.ccs.miami.edu/\n",
    "- **PyTorchæ–‡æ¡£**: https://pytorch.org/docs/\n",
    "\n",
    "---\n",
    "\n",
    "**æœ€åæ›´æ–°**: 2025-01-XX  \n",
    "**ç‰ˆæœ¬**: 1.0.0  \n",
    "**çŠ¶æ€**: âœ… å·²éªŒè¯ä¸è®ºæ–‡ä¸€è‡´"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
