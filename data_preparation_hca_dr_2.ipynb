{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60cbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ”§ HCA-DR Data Preprocessing - PLATE-LEVEL MATCHING VERSION\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Configuration:\n",
      "   LINCS data: D:\\ç§‘ç ”\\Models\\drugreflector\\datasets\\LINCS2020\n",
      "   Processed data: D:\\ç§‘ç ”\\Models\\drugreflector\\processed_data\n",
      "   Output: D:\\ç§‘ç ”\\Models\\drugreflector\\processed_data\\hca_dr_training_data_plate_matched.pkl\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ STARTING HCA-DR DATA PREPARATION (PLATE-MATCHED VERSION)\n",
      "================================================================================\n",
      "ğŸ“– Loading gene information...\n",
      "   âœ“ Total genes: 12,328\n",
      "   âœ“ Landmark genes: 978\n",
      "\n",
      "ğŸ“– Loading processed training data...\n",
      "   âœ“ Samples: 509,006\n",
      "   âœ“ Compounds: 10,107\n",
      "   âœ“ Genes: 978\n",
      "   âœ“ Using 'det_plate' as plate identifier\n",
      "   âœ“ Unique plates in training: 4756\n",
      "\n",
      "ğŸ“– Loading Level 3 DMSO control data...\n",
      "   âœ“ Total Level 3 instances: 3,026,460\n",
      "   âœ“ Filtering by pert_type: 102,696 control samples\n",
      "   Loading expression matrix (this may take a while)...\n",
      "   âœ“ Data shape: (978, 12328)\n",
      "   âš ï¸  Metadata count (102696) != data count (12328)\n",
      "   Taking first 12328 rows from filtered metadata\n",
      "   âœ“ Loaded 12,328 control samples\n",
      "   âœ“ Genes: 978\n",
      "   âœ“ Metadata matched successfully\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª Computing Plate-wise DMSO Control Means\n",
      "================================================================================\n",
      "   Using 'det_plate' as plate identifier\n",
      "   âœ“ Total unique plates: 4,919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Computing plate means: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4919/4919 [00:01<00:00, 2777.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   âœ“ Computed means for 4,919 plates\n",
      "   ğŸ“Š Samples per plate: mean=2.5, median=2, min=1, max=27\n",
      "\n",
      "ğŸ“‹ Building plate-to-cell mapping...\n",
      "   âœ“ Built mapping for 4919 plates\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¥ PLATE-LEVEL CONTEXT MATCHING (Critical Fix)\n",
      "================================================================================\n",
      "   Matching strategy:\n",
      "   1. Same plate DMSO (best)\n",
      "   2. Same cell, different plates (fallback)\n",
      "   3. Zero vector (missing)\n",
      "\n",
      "   Processing 509,006 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Matching contexts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 509006/509006 [00:42<00:00, 11857.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ğŸ“Š Matching Results:\n",
      "   âœ… Exact match (same plate): 431,324 (84.7%)\n",
      "   ğŸ”„ Fallback (same cell, diff plate): 77,682 (15.3%)\n",
      "   âŒ Missing: 0 (0.0%)\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Applying Rank-based INT Normalization\n",
      "================================================================================\n",
      "   Valid samples for normalization: 509,006 / 509,006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Normalizing genes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 978/978 [00:41<00:00, 23.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ğŸ“Š INT Validation (valid samples only):\n",
      "      â€¢ Mean per gene: -0.000029\n",
      "      â€¢ Std per gene: 0.999511\n",
      "      â€¢ Overall mean: -0.000029\n",
      "      â€¢ Overall std: 0.999597\n",
      "\n",
      "================================================================================\n",
      "ğŸ·ï¸  Building Cell Line ID Mapping\n",
      "================================================================================\n",
      "   âœ“ Built mapping for 57 cell lines\n",
      "\n",
      "ğŸ“‹ Assigning cell line IDs...\n",
      "   âœ“ Assigned IDs for 509,006 samples\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ Building Final HCA-DR Dataset\n",
      "================================================================================\n",
      "   Filtering samples without valid context...\n",
      "   Before: 509,006\n",
      "   After: 509,006\n",
      "   Removed: 0\n",
      "\n",
      "   âœ“ X_pert shape: (509006, 978)\n",
      "   âœ“ X_ctx shape: (509006, 978)\n",
      "   âœ“ y shape: (509006,)\n",
      "   âœ“ cell_ids shape: (509006,)\n",
      "\n",
      "ğŸ’¾ Saving HCA-DR dataset...\n",
      "   âœ“ Saved to: D:\\ç§‘ç ”\\Models\\drugreflector\\processed_data\\hca_dr_training_data_plate_matched.pkl\n",
      "   âœ“ File size: 3943.06 MB\n",
      "\n",
      "ğŸ“Š Creating visualization...\n",
      "   âœ“ Saved visualization to: D:\\ç§‘ç ”\\Models\\drugreflector\\visualizations\\hca_dr\\hca_dr_plate_matched_summary.png\n",
      "\n",
      "================================================================================\n",
      "âœ… HCA-DR DATA PREPROCESSING COMPLETE (PLATE-MATCHED)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Final Dataset Summary:\n",
      "   â€¢ Total samples: 509,006\n",
      "   â€¢ Compounds: 10,107\n",
      "   â€¢ Cell lines: 57\n",
      "   â€¢ Genes: 978\n",
      "\n",
      "ğŸ“‹ Matching Quality:\n",
      "   â€¢ Exact match (same plate): 84.7%\n",
      "   â€¢ Fallback (same cell): 15.3%\n",
      "   â€¢ Missing (filtered out): 0.0%\n",
      "\n",
      "ğŸ“ Output Files:\n",
      "   â€¢ Data: D:\\ç§‘ç ”\\Models\\drugreflector\\processed_data\\hca_dr_training_data_plate_matched.pkl\n",
      "   â€¢ Visualization: D:\\ç§‘ç ”\\Models\\drugreflector\\visualizations\\hca_dr\\hca_dr_plate_matched_summary.png\n",
      "\n",
      "ğŸ¯ Ready for HCA-DR model training with proper batch effect control!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HCA-DR (Hierarchical Cell-Aware DrugReflector) æ•°æ®é¢„å¤„ç† - æ¿çº§åŒ¹é…ä¿®å¤ç‰ˆ\n",
    "================================================================================\n",
    "\n",
    "è‡´å‘½é”™è¯¯ä¿®å¤ï¼šä½¿ç”¨æ¿çº§åŒ¹é…ï¼ˆPlate-level Matchingï¼‰è€Œéå…¨å±€å¹³å‡\n",
    "\n",
    "æ ¸å¿ƒæ”¹å˜ï¼š\n",
    "1. ä¸ºæ¯ä¸ªæ ·æœ¬åŒ¹é…å…¶æ‰€åœ¨ plate çš„ DMSO å¯¹ç…§\n",
    "2. å¦‚æœæ ·æœ¬æ‰€åœ¨ plate æ²¡æœ‰ DMSOï¼Œä½¿ç”¨åŒæ‰¹æ¬¡æˆ–åŒç»†èƒç³»çš„æœ€è¿‘ plate\n",
    "3. ä¿ç•™ plate-level çš„æ‰¹æ¬¡ä¿¡æ¯ï¼Œé¿å…å¼•å…¥å…¨å±€å¹³å‡çš„å™ªå£°\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import warnings\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾é£æ ¼\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# ==================== é…ç½®è·¯å¾„ ====================\n",
    "LINCS_DATA_DIR = Path(\"D:/ç§‘ç ”/Models/drugreflector/datasets/LINCS2020\")\n",
    "PROCESSED_DATA_DIR = Path(\"D:/ç§‘ç ”/Models/drugreflector/processed_data\")\n",
    "OUTPUT_DIR = Path(\"D:/ç§‘ç ”/Models/drugreflector/processed_data\")\n",
    "VIZ_DIR = Path(\"D:/ç§‘ç ”/Models/drugreflector/visualizations/hca_dr\")\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "VIZ_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# è¾“å…¥æ–‡ä»¶\n",
    "TRAINING_DATA_FILE = \"training_data_lincs2020_chemfiltered_1201_l.pkl\"\n",
    "LEVEL3_CTL_FILE = \"level3_beta_ctl_n188708x12328.gctx\"\n",
    "GENE_INFO_FILE = \"geneinfo_beta.txt\"\n",
    "INST_INFO_FILE = \"instinfo_beta.txt\"\n",
    "\n",
    "# è¾“å‡ºæ–‡ä»¶\n",
    "OUTPUT_FILE = \"hca_dr_training_data_plate_matched.pkl\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ”§ HCA-DR Data Preprocessing - PLATE-LEVEL MATCHING VERSION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nğŸ“ Configuration:\")\n",
    "print(f\"   LINCS data: {LINCS_DATA_DIR}\")\n",
    "print(f\"   Processed data: {PROCESSED_DATA_DIR}\")\n",
    "print(f\"   Output: {OUTPUT_DIR / OUTPUT_FILE}\\n\")\n",
    "\n",
    "\n",
    "# ==================== 1. åŠ è½½åŸºå› ä¿¡æ¯ ====================\n",
    "def load_gene_info(gene_file: Path) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"åŠ è½½åŸºå› ä¿¡æ¯å¹¶è·å–landmarkåŸºå› ç´¢å¼•\"\"\"\n",
    "    print(\"ğŸ“– Loading gene information...\")\n",
    "    gene_info = pd.read_csv(gene_file, sep='\\t')\n",
    "    \n",
    "    print(f\"   âœ“ Total genes: {len(gene_info):,}\")\n",
    "    landmark_mask = gene_info['feature_space'] == 'landmark'\n",
    "    landmark_indices = np.where(landmark_mask.values)[0]\n",
    "    print(f\"   âœ“ Landmark genes: {len(landmark_indices)}\")\n",
    "    \n",
    "    return gene_info, landmark_indices\n",
    "\n",
    "\n",
    "# ==================== 2. åŠ è½½è®­ç»ƒæ•°æ® ====================\n",
    "def load_training_data(training_path: Path) -> Dict:\n",
    "    \"\"\"åŠ è½½å·²å¤„ç†çš„è®­ç»ƒæ•°æ®\"\"\"\n",
    "    print(\"\\nğŸ“– Loading processed training data...\")\n",
    "    \n",
    "    with open(training_path, 'rb') as f:\n",
    "        training_data = pickle.load(f)\n",
    "    \n",
    "    meta = training_data['sample_meta']\n",
    "    print(f\"   âœ“ Samples: {len(training_data['X']):,}\")\n",
    "    print(f\"   âœ“ Compounds: {len(training_data['compound_names']):,}\")\n",
    "    print(f\"   âœ“ Genes: {training_data['X'].shape[1]}\")\n",
    "    \n",
    "    # ç¡®ä¿æœ‰ plate ä¿¡æ¯\n",
    "    plate_col = 'det_plate' if 'det_plate' in meta.columns else 'rna_plate'\n",
    "    print(f\"   âœ“ Using '{plate_col}' as plate identifier\")\n",
    "    print(f\"   âœ“ Unique plates in training: {meta[plate_col].nunique()}\")\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "\n",
    "# ==================== 3. åŠ è½½ Level 3 DMSO æ•°æ® ====================\n",
    "def load_level3_controls(level3_file: Path, \n",
    "                         inst_file: Path,\n",
    "                         landmark_indices: np.ndarray) -> Tuple[np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"åŠ è½½Level 3 DMSOå¯¹ç…§æ•°æ®\"\"\"\n",
    "    print(\"\\nğŸ“– Loading Level 3 DMSO control data...\")\n",
    "    \n",
    "    # åŠ è½½å®ä¾‹ä¿¡æ¯\n",
    "    level3_meta_all = pd.read_csv(inst_file, sep='\\t', low_memory=False)\n",
    "    print(f\"   âœ“ Total Level 3 instances: {len(level3_meta_all):,}\")\n",
    "    \n",
    "    # æ£€æŸ¥å¯èƒ½çš„ control æ ‡è¯†åˆ—\n",
    "    if 'pert_type' in level3_meta_all.columns:\n",
    "        control_mask = level3_meta_all['pert_type'].isin(['ctl_vehicle', 'control'])\n",
    "        print(f\"   âœ“ Filtering by pert_type: {control_mask.sum():,} control samples\")\n",
    "    elif 'pert_iname' in level3_meta_all.columns:\n",
    "        control_mask = level3_meta_all['pert_iname'].str.contains('DMSO|control', case=False, na=False)\n",
    "        print(f\"   âœ“ Filtering by pert_iname: {control_mask.sum():,} control samples\")\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰æ˜ç¡®æ ‡è¯†ï¼Œå‡è®¾æ–‡ä»¶åå·²ç»å‘Šè¯‰æˆ‘ä»¬è¿™æ˜¯ control æ•°æ®\n",
    "        # ä½¿ç”¨æ•°æ®çŸ©é˜µçš„åˆ—æ•°æ¥ç¡®å®š\n",
    "        print(f\"   âš ï¸  No control identifier found, assuming all samples in data matrix are controls\")\n",
    "        control_mask = None\n",
    "    \n",
    "    # åŠ è½½æ•°æ®\n",
    "    print(\"   Loading expression matrix (this may take a while)...\")\n",
    "    with h5py.File(level3_file, 'r') as f:\n",
    "        # åªåŠ è½½landmarkåŸºå› \n",
    "        data = f['0/DATA/0/matrix'][:]\n",
    "        data_landmark = data[landmark_indices, :]\n",
    "        print(f\"   âœ“ Data shape: {data_landmark.shape}\")\n",
    "    \n",
    "    # æ ¹æ®æ•°æ®çŸ©é˜µçš„å¤§å°æ¥åŒ¹é… metadata\n",
    "    n_samples_in_data = data_landmark.shape[1]\n",
    "    \n",
    "    if control_mask is not None:\n",
    "        level3_meta = level3_meta_all[control_mask].reset_index(drop=True)\n",
    "        \n",
    "        # å¦‚æœè¿‡æ»¤åä»ä¸åŒ¹é…ï¼Œå–å‰ n_samples_in_data è¡Œ\n",
    "        if len(level3_meta) != n_samples_in_data:\n",
    "            print(f\"   âš ï¸  Metadata count ({len(level3_meta)}) != data count ({n_samples_in_data})\")\n",
    "            print(f\"   Taking first {n_samples_in_data} rows from filtered metadata\")\n",
    "            level3_meta = level3_meta.iloc[:n_samples_in_data].reset_index(drop=True)\n",
    "    else:\n",
    "        # ç›´æ¥å–å‰ n_samples_in_data è¡Œ\n",
    "        level3_meta = level3_meta_all.iloc[:n_samples_in_data].reset_index(drop=True)\n",
    "    \n",
    "    # éªŒè¯\n",
    "    assert len(level3_meta) == data_landmark.shape[1], \\\n",
    "        f\"Metadataå’Œæ•°æ®ç»´åº¦ä¸åŒ¹é…: {len(level3_meta)} vs {data_landmark.shape[1]}\"\n",
    "    \n",
    "    print(f\"   âœ“ Loaded {data_landmark.shape[1]:,} control samples\")\n",
    "    print(f\"   âœ“ Genes: {data_landmark.shape[0]}\")\n",
    "    print(f\"   âœ“ Metadata matched successfully\")\n",
    "    \n",
    "    return data_landmark.T, level3_meta\n",
    "\n",
    "\n",
    "# ==================== 4. è®¡ç®—æ¯ä¸ª Plate çš„ DMSO å‡å€¼ ====================\n",
    "def compute_plate_dmso_means(level3_data: np.ndarray,\n",
    "                            level3_meta: pd.DataFrame) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ¯ä¸ªplateçš„DMSOå¯¹ç…§å‡å€¼\n",
    "    \n",
    "    å…³é”®ï¼šè¿™æ˜¯æ‰¹æ¬¡æ•ˆåº”æ§åˆ¶çš„æ ¸å¿ƒ - ä¿æŒplate-levelçš„ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ§ª Computing Plate-wise DMSO Control Means\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    plate_col = 'det_plate' if 'det_plate' in level3_meta.columns else 'rna_plate'\n",
    "    print(f\"   Using '{plate_col}' as plate identifier\")\n",
    "    \n",
    "    unique_plates = level3_meta[plate_col].unique()\n",
    "    print(f\"   âœ“ Total unique plates: {len(unique_plates):,}\")\n",
    "    \n",
    "    plate_means = {}\n",
    "    plate_sample_counts = []\n",
    "    \n",
    "    for plate in tqdm(unique_plates, desc=\"   Computing plate means\"):\n",
    "        plate_mask = level3_meta[plate_col] == plate\n",
    "        plate_data = level3_data[plate_mask]\n",
    "        \n",
    "        if len(plate_data) > 0:\n",
    "            plate_mean = np.mean(plate_data, axis=0).astype(np.float32)\n",
    "            plate_means[plate] = plate_mean\n",
    "            plate_sample_counts.append(len(plate_data))\n",
    "    \n",
    "    print(f\"\\n   âœ“ Computed means for {len(plate_means):,} plates\")\n",
    "    print(f\"   ğŸ“Š Samples per plate: mean={np.mean(plate_sample_counts):.1f}, \"\n",
    "          f\"median={np.median(plate_sample_counts):.0f}, \"\n",
    "          f\"min={np.min(plate_sample_counts):.0f}, \"\n",
    "          f\"max={np.max(plate_sample_counts):.0f}\")\n",
    "    \n",
    "    return plate_means\n",
    "\n",
    "\n",
    "# ==================== 5. æ„å»º Plate -> Cell æ˜ å°„ ====================\n",
    "def build_plate_to_cell_mapping(level3_meta: pd.DataFrame) -> Dict[str, List[str]]:\n",
    "    \"\"\"æ„å»ºplateåˆ°ç»†èƒç³»çš„æ˜ å°„ï¼Œç”¨äºfallbackç­–ç•¥\"\"\"\n",
    "    print(\"\\nğŸ“‹ Building plate-to-cell mapping...\")\n",
    "    \n",
    "    plate_col = 'det_plate' if 'det_plate' in level3_meta.columns else 'rna_plate'\n",
    "    cell_col = 'cell_iname' if 'cell_iname' in level3_meta.columns else 'cell_mfc_name'\n",
    "    \n",
    "    plate_to_cells = defaultdict(set)\n",
    "    \n",
    "    for _, row in level3_meta.iterrows():\n",
    "        plate = row[plate_col]\n",
    "        cell = row[cell_col]\n",
    "        if pd.notna(plate) and pd.notna(cell):\n",
    "            plate_to_cells[plate].add(cell)\n",
    "    \n",
    "    # è½¬æ¢ä¸ºlist\n",
    "    plate_to_cells = {k: list(v) for k, v in plate_to_cells.items()}\n",
    "    \n",
    "    print(f\"   âœ“ Built mapping for {len(plate_to_cells)} plates\")\n",
    "    \n",
    "    return plate_to_cells\n",
    "\n",
    "\n",
    "# ==================== 6. ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šæ¿çº§åŒ¹é… ====================\n",
    "def match_plate_level_contexts(training_meta: pd.DataFrame,\n",
    "                               plate_dmso_means: Dict[str, np.ndarray],\n",
    "                               plate_to_cells: Dict[str, List[str]],\n",
    "                               n_genes: int = 978) -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    ğŸ”¥ CRITICAL FIX: Plate-level context matching\n",
    "    \n",
    "    ä¸ºæ¯ä¸ªè®­ç»ƒæ ·æœ¬åŒ¹é…å…¶æ‰€åœ¨plateçš„DMSOå¯¹ç…§\n",
    "    \n",
    "    ç­–ç•¥ï¼š\n",
    "    1. ä¼˜å…ˆï¼šä½¿ç”¨æ ·æœ¬æ‰€åœ¨plateçš„DMSOå‡å€¼ï¼ˆæœ€å‡†ç¡®ï¼‰\n",
    "    2. Fallback 1ï¼šå¦‚æœplateæ²¡æœ‰DMSOï¼Œä½¿ç”¨åŒç»†èƒç³»å…¶ä»–platesçš„å‡å€¼\n",
    "    3. Fallback 2ï¼šå¦‚æœç»†èƒç³»æ²¡æœ‰ä»»ä½•DMSOï¼Œä½¿ç”¨é›¶å‘é‡ï¼ˆä¼šè¢«è¿‡æ»¤ï¼‰\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        training_meta: è®­ç»ƒæ•°æ®çš„å…ƒä¿¡æ¯\n",
    "        plate_dmso_means: æ¯ä¸ªplateçš„DMSOå‡å€¼ {plate_id: mean_vector}\n",
    "        plate_to_cells: plateåˆ°ç»†èƒç³»çš„æ˜ å°„\n",
    "        n_genes: åŸºå› æ•°é‡\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "        X_ctx: ä¸Šä¸‹æ–‡çŸ©é˜µ (n_samples, n_genes)\n",
    "        matching_quality: åŒ¹é…è´¨é‡æ ‡è®° (n_samples,)\n",
    "            0: å®Œç¾åŒ¹é…ï¼ˆsame plateï¼‰\n",
    "            1: Fallbackï¼ˆsame cell, different plateï¼‰\n",
    "            2: Missingï¼ˆæ— åŒ¹é…ï¼‰\n",
    "        matching_stats: ç»Ÿè®¡ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ”¥ PLATE-LEVEL CONTEXT MATCHING (Critical Fix)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    n_samples = len(training_meta)\n",
    "    \n",
    "    # ç¡®å®šåˆ—å\n",
    "    plate_col = 'det_plate' if 'det_plate' in training_meta.columns else 'rna_plate'\n",
    "    cell_col = 'cell_iname' if 'cell_iname' in training_meta.columns else 'cell_mfc_name'\n",
    "    \n",
    "    print(f\"   Matching strategy:\")\n",
    "    print(f\"   1. Same plate DMSO (best)\")\n",
    "    print(f\"   2. Same cell, different plates (fallback)\")\n",
    "    print(f\"   3. Zero vector (missing)\")\n",
    "    print(f\"\\n   Processing {n_samples:,} samples...\")\n",
    "    \n",
    "    # åˆå§‹åŒ–\n",
    "    X_ctx = np.zeros((n_samples, n_genes), dtype=np.float32)\n",
    "    matching_quality = np.zeros(n_samples, dtype=np.int8)\n",
    "    \n",
    "    # æ„å»ºç»†èƒç³»åˆ°å…¶æ‰€æœ‰platesçš„æ˜ å°„ï¼ˆç”¨äºfallbackï¼‰\n",
    "    cell_to_plates = defaultdict(list)\n",
    "    for plate, cells in plate_to_cells.items():\n",
    "        for cell in cells:\n",
    "            if plate in plate_dmso_means:  # åªæ·»åŠ æœ‰DMSOæ•°æ®çš„plate\n",
    "                cell_to_plates[cell].append(plate)\n",
    "    \n",
    "    # ç»Ÿè®¡å˜é‡\n",
    "    n_exact_match = 0\n",
    "    n_fallback = 0\n",
    "    n_missing = 0\n",
    "    \n",
    "    # é€æ ·æœ¬åŒ¹é…\n",
    "    for idx in tqdm(range(n_samples), desc=\"   Matching contexts\"):\n",
    "        row = training_meta.iloc[idx]\n",
    "        sample_plate = row[plate_col]\n",
    "        sample_cell = row[cell_col]\n",
    "        \n",
    "        # ç­–ç•¥1: ä½¿ç”¨åŒplateçš„DMSOï¼ˆæœ€ä½³ï¼‰\n",
    "        if sample_plate in plate_dmso_means:\n",
    "            X_ctx[idx] = plate_dmso_means[sample_plate]\n",
    "            matching_quality[idx] = 0\n",
    "            n_exact_match += 1\n",
    "        \n",
    "        # ç­–ç•¥2: Fallback - ä½¿ç”¨åŒç»†èƒç³»å…¶ä»–platesçš„å¹³å‡\n",
    "        elif sample_cell in cell_to_plates and len(cell_to_plates[sample_cell]) > 0:\n",
    "            cell_plates = cell_to_plates[sample_cell]\n",
    "            cell_plate_means = [plate_dmso_means[p] for p in cell_plates]\n",
    "            X_ctx[idx] = np.mean(cell_plate_means, axis=0)\n",
    "            matching_quality[idx] = 1\n",
    "            n_fallback += 1\n",
    "        \n",
    "        # ç­–ç•¥3: æ— åŒ¹é… - é›¶å‘é‡\n",
    "        else:\n",
    "            X_ctx[idx] = np.zeros(n_genes, dtype=np.float32)\n",
    "            matching_quality[idx] = 2\n",
    "            n_missing += 1\n",
    "    \n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"\\n   ğŸ“Š Matching Results:\")\n",
    "    print(f\"   âœ… Exact match (same plate): {n_exact_match:,} ({n_exact_match/n_samples*100:.1f}%)\")\n",
    "    print(f\"   ğŸ”„ Fallback (same cell, diff plate): {n_fallback:,} ({n_fallback/n_samples*100:.1f}%)\")\n",
    "    print(f\"   âŒ Missing: {n_missing:,} ({n_missing/n_samples*100:.1f}%)\")\n",
    "    \n",
    "    matching_stats = {\n",
    "        'n_exact_match': n_exact_match,\n",
    "        'n_fallback': n_fallback,\n",
    "        'n_missing': n_missing,\n",
    "        'pct_exact': n_exact_match / n_samples * 100,\n",
    "        'pct_fallback': n_fallback / n_samples * 100,\n",
    "        'pct_missing': n_missing / n_samples * 100\n",
    "    }\n",
    "    \n",
    "    return X_ctx, matching_quality, matching_stats\n",
    "\n",
    "\n",
    "# ==================== 7. åº”ç”¨ Rank-based INT å½’ä¸€åŒ– ====================\n",
    "def apply_rank_based_int_per_sample(X_ctx: np.ndarray,\n",
    "                                    matching_quality: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    å¯¹æ¯ä¸ªåŸºå› åº”ç”¨Rank-based Inverse Normal Transformation\n",
    "    \n",
    "    é‡è¦ï¼šåªåœ¨æœ‰æ•ˆæ ·æœ¬ï¼ˆmatching_quality < 2ï¼‰ä¸Šè®¡ç®—æ’å\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š Applying Rank-based INT Normalization\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    n_samples, n_genes = X_ctx.shape\n",
    "    \n",
    "    # åªåœ¨æœ‰æ•ˆæ ·æœ¬ä¸Šè¿›è¡Œå½’ä¸€åŒ–\n",
    "    valid_mask = matching_quality < 2\n",
    "    n_valid = valid_mask.sum()\n",
    "    \n",
    "    print(f\"   Valid samples for normalization: {n_valid:,} / {n_samples:,}\")\n",
    "    \n",
    "    X_ctx_int = np.zeros_like(X_ctx)\n",
    "    \n",
    "    for g in tqdm(range(n_genes), desc=\"   Normalizing genes\"):\n",
    "        gene_values = X_ctx[valid_mask, g]\n",
    "        \n",
    "        if len(gene_values) > 1:\n",
    "            # è®¡ç®—æ’å\n",
    "            ranks = rankdata(gene_values, method='average')\n",
    "            \n",
    "            # è½¬æ¢ä¸ºæ ‡å‡†æ­£æ€åˆ†ä½æ•°\n",
    "            quantiles = ranks / (len(gene_values) + 1)\n",
    "            int_values = stats.norm.ppf(quantiles)\n",
    "            \n",
    "            # å¡«å……åˆ°å®Œæ•´çŸ©é˜µ\n",
    "            X_ctx_int[valid_mask, g] = int_values\n",
    "    \n",
    "    # éªŒè¯å½’ä¸€åŒ–\n",
    "    valid_data = X_ctx_int[valid_mask]\n",
    "    print(f\"\\n   ğŸ“Š INT Validation (valid samples only):\")\n",
    "    print(f\"      â€¢ Mean per gene: {valid_data.mean(axis=0).mean():.6f}\")\n",
    "    print(f\"      â€¢ Std per gene: {valid_data.std(axis=0).mean():.6f}\")\n",
    "    print(f\"      â€¢ Overall mean: {valid_data.mean():.6f}\")\n",
    "    print(f\"      â€¢ Overall std: {valid_data.std():.6f}\")\n",
    "    \n",
    "    return X_ctx_int\n",
    "\n",
    "\n",
    "# ==================== 8. æ„å»ºç»†èƒç³» ID æ˜ å°„ ====================\n",
    "def build_cell_id_mapping(training_meta: pd.DataFrame,\n",
    "                         matching_quality: np.ndarray) -> Dict[str, int]:\n",
    "    \"\"\"æ„å»ºç»†èƒç³»IDæ˜ å°„\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ·ï¸  Building Cell Line ID Mapping\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    cell_col = 'cell_iname' if 'cell_iname' in training_meta.columns else 'cell_mfc_name'\n",
    "    \n",
    "    # åªè€ƒè™‘æœ‰æœ‰æ•ˆåŒ¹é…çš„ç»†èƒç³»\n",
    "    valid_mask = matching_quality < 2\n",
    "    valid_cells = training_meta[valid_mask][cell_col].unique()\n",
    "    \n",
    "    # æ„å»ºæ˜ å°„\n",
    "    sorted_cells = sorted(list(valid_cells))\n",
    "    cell_id_to_idx = {cell: idx for idx, cell in enumerate(sorted_cells)}\n",
    "    \n",
    "    print(f\"   âœ“ Built mapping for {len(cell_id_to_idx)} cell lines\")\n",
    "    \n",
    "    return cell_id_to_idx\n",
    "\n",
    "\n",
    "# ==================== 9. åˆ†é…ç»†èƒç³» ID ====================\n",
    "def assign_cell_ids(training_meta: pd.DataFrame,\n",
    "                   cell_id_to_idx: Dict[str, int]) -> np.ndarray:\n",
    "    \"\"\"ä¸ºæ¯ä¸ªæ ·æœ¬åˆ†é…ç»†èƒç³»ID\"\"\"\n",
    "    print(\"\\nğŸ“‹ Assigning cell line IDs...\")\n",
    "    \n",
    "    cell_col = 'cell_iname' if 'cell_iname' in training_meta.columns else 'cell_mfc_name'\n",
    "    \n",
    "    cell_ids = np.array([\n",
    "        cell_id_to_idx.get(cell, -1) \n",
    "        for cell in training_meta[cell_col]\n",
    "    ], dtype=np.int32)\n",
    "    \n",
    "    print(f\"   âœ“ Assigned IDs for {(cell_ids >= 0).sum():,} samples\")\n",
    "    \n",
    "    return cell_ids\n",
    "\n",
    "\n",
    "# ==================== 10. æ„å»ºæœ€ç»ˆæ•°æ®é›† ====================\n",
    "def build_final_dataset(training_data: Dict,\n",
    "                       X_ctx: np.ndarray,\n",
    "                       matching_quality: np.ndarray,\n",
    "                       cell_ids: np.ndarray,\n",
    "                       cell_id_to_idx: Dict[str, int],\n",
    "                       matching_stats: Dict,\n",
    "                       filter_missing: bool = True) -> Dict:\n",
    "    \"\"\"æ„å»ºæœ€ç»ˆçš„HCA-DRæ•°æ®é›†\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸš€ Building Final HCA-DR Dataset\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if filter_missing:\n",
    "        # è¿‡æ»¤æ‰æ²¡æœ‰æœ‰æ•ˆåŒ¹é…çš„æ ·æœ¬\n",
    "        valid_mask = matching_quality < 2\n",
    "        n_before = len(matching_quality)\n",
    "        n_after = valid_mask.sum()\n",
    "        \n",
    "        print(f\"   Filtering samples without valid context...\")\n",
    "        print(f\"   Before: {n_before:,}\")\n",
    "        print(f\"   After: {n_after:,}\")\n",
    "        print(f\"   Removed: {n_before - n_after:,}\")\n",
    "        \n",
    "        # è¿‡æ»¤æ•°æ®\n",
    "        X_pert = training_data['X'][valid_mask]\n",
    "        X_ctx_filtered = X_ctx[valid_mask]\n",
    "        cell_ids_filtered = cell_ids[valid_mask]\n",
    "        matching_quality_filtered = matching_quality[valid_mask]\n",
    "        folds = training_data['folds'][valid_mask]\n",
    "        sample_meta = training_data['sample_meta'][valid_mask].reset_index(drop=True)\n",
    "        \n",
    "        # é‡å»ºåŒ–åˆç‰©æ ‡ç­¾\n",
    "        unique_perts = sorted(sample_meta['pert_id'].unique())\n",
    "        new_pert_to_idx = {pert: idx for idx, pert in enumerate(unique_perts)}\n",
    "        y = np.array([new_pert_to_idx[p] for p in sample_meta['pert_id']], dtype=np.int32)\n",
    "        \n",
    "        compound_names = unique_perts\n",
    "        pert_to_idx = new_pert_to_idx\n",
    "    else:\n",
    "        X_pert = training_data['X']\n",
    "        X_ctx_filtered = X_ctx\n",
    "        cell_ids_filtered = cell_ids\n",
    "        matching_quality_filtered = matching_quality\n",
    "        folds = training_data['folds']\n",
    "        sample_meta = training_data['sample_meta']\n",
    "        y = training_data['y']\n",
    "        compound_names = training_data['compound_names']\n",
    "        pert_to_idx = training_data['pert_to_idx']\n",
    "    \n",
    "    print(f\"\\n   âœ“ X_pert shape: {X_pert.shape}\")\n",
    "    print(f\"   âœ“ X_ctx shape: {X_ctx_filtered.shape}\")\n",
    "    print(f\"   âœ“ y shape: {y.shape}\")\n",
    "    print(f\"   âœ“ cell_ids shape: {cell_ids_filtered.shape}\")\n",
    "    \n",
    "    # æ„å»ºæ•°æ®å­—å…¸\n",
    "    hca_dr_data = {\n",
    "        # æ ¸å¿ƒæ•°æ®\n",
    "        'X_pert': X_pert,\n",
    "        'X_ctx': X_ctx_filtered,\n",
    "        'y': y,\n",
    "        'cell_ids': cell_ids_filtered,\n",
    "        'matching_quality': matching_quality_filtered,\n",
    "        'folds': folds,\n",
    "        \n",
    "        # å…ƒæ•°æ®\n",
    "        'sample_meta': sample_meta,\n",
    "        'gene_names': training_data['gene_names'],\n",
    "        'compound_names': compound_names,\n",
    "        'pert_to_idx': pert_to_idx,\n",
    "        'cell_id_to_idx': cell_id_to_idx,\n",
    "        'idx_to_cell_id': {v: k for k, v in cell_id_to_idx.items()},\n",
    "        \n",
    "        # ç»Ÿè®¡ä¿¡æ¯\n",
    "        'n_samples': len(X_pert),\n",
    "        'n_compounds': len(compound_names),\n",
    "        'n_genes': X_pert.shape[1],\n",
    "        'n_cell_lines': len(cell_id_to_idx),\n",
    "        \n",
    "        # åŒ¹é…è´¨é‡ç»Ÿè®¡\n",
    "        'matching_stats': matching_stats,\n",
    "        \n",
    "        # ç‰ˆæœ¬ä¿¡æ¯\n",
    "        'version': 'plate_matched',\n",
    "        'description': 'HCA-DR data with plate-level context matching (batch effect corrected)'\n",
    "    }\n",
    "    \n",
    "    return hca_dr_data\n",
    "\n",
    "\n",
    "# ==================== 11. å¯è§†åŒ–åˆ†æ ====================\n",
    "def visualize_matching_quality(hca_dr_data: Dict, output_dir: Path):\n",
    "    \"\"\"å¯è§†åŒ–åŒ¹é…è´¨é‡å’Œæ‰¹æ¬¡æ•ˆåº”æ§åˆ¶\"\"\"\n",
    "    print(\"\\nğŸ“Š Creating visualization...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. åŒ¹é…è´¨é‡åˆ†å¸ƒ\n",
    "    ax1 = axes[0, 0]\n",
    "    quality_labels = ['Exact\\n(same plate)', 'Fallback\\n(same cell)', 'Missing']\n",
    "    quality_counts = [\n",
    "        (hca_dr_data['matching_quality'] == 0).sum(),\n",
    "        (hca_dr_data['matching_quality'] == 1).sum(),\n",
    "        (hca_dr_data['matching_quality'] == 2).sum()\n",
    "    ]\n",
    "    colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "    bars = ax1.bar(quality_labels, quality_counts, color=colors, alpha=0.7)\n",
    "    ax1.set_ylabel('Number of Samples')\n",
    "    ax1.set_title('Context Matching Quality', fontweight='bold')\n",
    "    for bar, val in zip(bars, quality_counts):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, height,\n",
    "                f'{val:,}\\n({val/len(hca_dr_data[\"matching_quality\"])*100:.1f}%)',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    # 2. X_ctx åˆ†å¸ƒ\n",
    "    ax2 = axes[0, 1]\n",
    "    sample_ctx = hca_dr_data['X_ctx'][np.random.choice(len(hca_dr_data['X_ctx']), \n",
    "                                                         min(10000, len(hca_dr_data['X_ctx'])), \n",
    "                                                         replace=False)].flatten()\n",
    "    ax2.hist(sample_ctx, bins=100, alpha=0.7, edgecolor='black', color='steelblue')\n",
    "    ax2.set_xlabel('X_ctx Value')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('X_ctx Distribution (after INT)', fontweight='bold')\n",
    "    ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='Mean=0')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. æ¯ä¸ªç»†èƒç³»çš„æ ·æœ¬æ•°\n",
    "    ax3 = axes[0, 2]\n",
    "    cell_counts = pd.Series(hca_dr_data['cell_ids']).value_counts().sort_values(ascending=True)\n",
    "    top_cells = cell_counts.tail(15)\n",
    "    cell_names = [hca_dr_data['idx_to_cell_id'][cid] for cid in top_cells.index]\n",
    "    ax3.barh(range(len(top_cells)), top_cells.values, color='coral')\n",
    "    ax3.set_yticks(range(len(top_cells)))\n",
    "    ax3.set_yticklabels(cell_names, fontsize=9)\n",
    "    ax3.set_xlabel('Number of Samples')\n",
    "    ax3.set_title('Top 15 Cell Lines by Sample Count', fontweight='bold')\n",
    "    \n",
    "    # 4. X_pert vs X_ctx ç›¸å…³æ€§\n",
    "    ax4 = axes[1, 0]\n",
    "    sample_idx = np.random.choice(len(hca_dr_data['X_pert']), \n",
    "                                  min(5000, len(hca_dr_data['X_pert'])), \n",
    "                                  replace=False)\n",
    "    pert_sample = hca_dr_data['X_pert'][sample_idx].flatten()\n",
    "    ctx_sample = hca_dr_data['X_ctx'][sample_idx].flatten()\n",
    "    ax4.hexbin(pert_sample, ctx_sample, gridsize=50, cmap='YlOrRd', mincnt=1)\n",
    "    ax4.set_xlabel('X_pert Value')\n",
    "    ax4.set_ylabel('X_ctx Value')\n",
    "    ax4.set_title('X_pert vs X_ctx Correlation', fontweight='bold')\n",
    "    plt.colorbar(ax4.collections[0], ax=ax4, label='Count')\n",
    "    \n",
    "    # 5. åŒ¹é…è´¨é‡ pie chart\n",
    "    ax5 = axes[1, 1]\n",
    "    stats = hca_dr_data['matching_stats']\n",
    "    sizes = [stats['n_exact_match'], stats['n_fallback']]\n",
    "    labels = [f\"Exact Match\\n{stats['pct_exact']:.1f}%\", \n",
    "              f\"Fallback\\n{stats['pct_fallback']:.1f}%\"]\n",
    "    ax5.pie(sizes, labels=labels, colors=['#2ecc71', '#f39c12'], \n",
    "            autopct='%d', startangle=90)\n",
    "    ax5.set_title('Matching Strategy Distribution', fontweight='bold')\n",
    "    \n",
    "    # 6. Cross-validation fold åˆ†å¸ƒ\n",
    "    ax6 = axes[1, 2]\n",
    "    fold_counts = pd.Series(hca_dr_data['folds']).value_counts().sort_index()\n",
    "    bars = ax6.bar(fold_counts.index, fold_counts.values, \n",
    "                   color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    ax6.set_xlabel('Fold')\n",
    "    ax6.set_ylabel('Number of Samples')\n",
    "    ax6.set_title('Cross-Validation Fold Distribution', fontweight='bold')\n",
    "    for bar, val in zip(bars, fold_counts.values):\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2, val, \n",
    "                f'{val:,}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'hca_dr_plate_matched_summary.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   âœ“ Saved visualization to: {output_dir / 'hca_dr_plate_matched_summary.png'}\")\n",
    "\n",
    "\n",
    "# ==================== 12. ä¸»æµç¨‹ ====================\n",
    "def main():\n",
    "    \"\"\"ä¸»æµç¨‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸš€ STARTING HCA-DR DATA PREPARATION (PLATE-MATCHED VERSION)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. åŠ è½½åŸºå› ä¿¡æ¯\n",
    "    gene_info, landmark_indices = load_gene_info(LINCS_DATA_DIR / GENE_INFO_FILE)\n",
    "    \n",
    "    # 2. åŠ è½½è®­ç»ƒæ•°æ®\n",
    "    training_data = load_training_data(PROCESSED_DATA_DIR / TRAINING_DATA_FILE)\n",
    "    \n",
    "    # 3. åŠ è½½ Level 3 DMSO æ•°æ®\n",
    "    level3_data, level3_meta = load_level3_controls(\n",
    "        LINCS_DATA_DIR / LEVEL3_CTL_FILE,\n",
    "        LINCS_DATA_DIR / INST_INFO_FILE,\n",
    "        landmark_indices\n",
    "    )\n",
    "    \n",
    "    # 4. è®¡ç®—æ¯ä¸ª Plate çš„ DMSO å‡å€¼\n",
    "    plate_dmso_means = compute_plate_dmso_means(level3_data, level3_meta)\n",
    "    \n",
    "    # 5. æ„å»º Plate -> Cell æ˜ å°„\n",
    "    plate_to_cells = build_plate_to_cell_mapping(level3_meta)\n",
    "    \n",
    "    # 6. ğŸ”¥ æ¿çº§åŒ¹é…ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰\n",
    "    X_ctx_raw, matching_quality, matching_stats = match_plate_level_contexts(\n",
    "        training_data['sample_meta'],\n",
    "        plate_dmso_means,\n",
    "        plate_to_cells,\n",
    "        n_genes=978\n",
    "    )\n",
    "    \n",
    "    # 7. åº”ç”¨ INT å½’ä¸€åŒ–\n",
    "    X_ctx_int = apply_rank_based_int_per_sample(X_ctx_raw, matching_quality)\n",
    "    \n",
    "    # 8. æ„å»ºç»†èƒç³» ID æ˜ å°„\n",
    "    cell_id_to_idx = build_cell_id_mapping(\n",
    "        training_data['sample_meta'], \n",
    "        matching_quality\n",
    "    )\n",
    "    \n",
    "    # 9. åˆ†é…ç»†èƒç³» ID\n",
    "    cell_ids = assign_cell_ids(training_data['sample_meta'], cell_id_to_idx)\n",
    "    \n",
    "    # 10. æ„å»ºæœ€ç»ˆæ•°æ®é›†\n",
    "    hca_dr_data = build_final_dataset(\n",
    "        training_data,\n",
    "        X_ctx_int,\n",
    "        matching_quality,\n",
    "        cell_ids,\n",
    "        cell_id_to_idx,\n",
    "        matching_stats,\n",
    "        filter_missing=True\n",
    "    )\n",
    "    \n",
    "    # 11. ä¿å­˜æ•°æ®\n",
    "    output_path = OUTPUT_DIR / OUTPUT_FILE\n",
    "    print(f\"\\nğŸ’¾ Saving HCA-DR dataset...\")\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(hca_dr_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    file_size_mb = output_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"   âœ“ Saved to: {output_path}\")\n",
    "    print(f\"   âœ“ File size: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "    # 12. å¯è§†åŒ–\n",
    "    visualize_matching_quality(hca_dr_data, VIZ_DIR)\n",
    "    \n",
    "    # 13. æœ€ç»ˆæ€»ç»“\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ… HCA-DR DATA PREPROCESSING COMPLETE (PLATE-MATCHED)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nğŸ“Š Final Dataset Summary:\")\n",
    "    print(f\"   â€¢ Total samples: {hca_dr_data['n_samples']:,}\")\n",
    "    print(f\"   â€¢ Compounds: {hca_dr_data['n_compounds']:,}\")\n",
    "    print(f\"   â€¢ Cell lines: {hca_dr_data['n_cell_lines']}\")\n",
    "    print(f\"   â€¢ Genes: {hca_dr_data['n_genes']}\")\n",
    "    print(f\"\\nğŸ“‹ Matching Quality:\")\n",
    "    print(f\"   â€¢ Exact match (same plate): {matching_stats['pct_exact']:.1f}%\")\n",
    "    print(f\"   â€¢ Fallback (same cell): {matching_stats['pct_fallback']:.1f}%\")\n",
    "    print(f\"   â€¢ Missing (filtered out): {matching_stats['pct_missing']:.1f}%\")\n",
    "    print(f\"\\nğŸ“ Output Files:\")\n",
    "    print(f\"   â€¢ Data: {output_path}\")\n",
    "    print(f\"   â€¢ Visualization: {VIZ_DIR / 'hca_dr_plate_matched_summary.png'}\")\n",
    "    print(f\"\\nğŸ¯ Ready for HCA-DR model training with proper batch effect control!\")\n",
    "    \n",
    "    return hca_dr_data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hca_dr_data = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
