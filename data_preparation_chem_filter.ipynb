{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7ab6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ”¬ APPLYING CHEMICAL FILTERS TO TRAINING DATA\n",
      "================================================================================\n",
      "\n",
      "ğŸ“– Loading training data...\n",
      "   âœ“ Loaded: 583,491 samples, 13,823 compounds\n",
      "   âœ“ Training data contains: 13,823 unique compounds\n",
      "ğŸ“– Loading NIBR filters from: SubstructureFilter_HitTriaging_wPubChemExamples.csv\n",
      "   âœ“ Loaded 444 NIBR filter patterns\n",
      "   âœ“ Successfully added 444 NIBR filters to catalog\n",
      "================================================================================\n",
      "ğŸ§ª Chemical Filter Initialized\n",
      "================================================================================\n",
      "Based on DrugReflector SI (page 2)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“– Loading compound information...\n",
      "   âœ“ Loaded 39,321 compounds\n",
      "   âœ“ Columns: ['pert_id', 'cmap_name', 'target', 'moa', 'canonical_smiles', 'inchi_key', 'compound_aliases']\n",
      "   âœ“ Using 'canonical_smiles' for molecular structures\n",
      "   âœ“ Compounds with valid SMILES: 33,531\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª APPLYING ALL CHEMICAL FILTERS\n",
      "================================================================================\n",
      "\n",
      "âš ï¸  Filtering only 13,823 compounds present in training data\n",
      "   Compounds to check: 18,187\n",
      "Initial compounds: 18,187\n",
      "\n",
      "================================================================================\n",
      "CHEMICAL FILTER 1: Molecular Weight (60-1000 Da)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:50:56] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:56] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:56] restricted\n",
      "[19:50:56] ^\n",
      "[19:50:56] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:56] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:56] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:56] restricted\n",
      "[19:50:56] ^\n",
      "[19:50:56] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:56] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:56] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:56] restricted\n",
      "[19:50:56] ^\n",
      "[19:50:56] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:58] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:58] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:58] restricted\n",
      "[19:50:58] ^\n",
      "[19:50:58] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Passed: 13,429 compounds\n",
      "  âœ— Failed (out of MW range): 66 compounds\n",
      "  âš ï¸  No SMILES: 331 compounds\n",
      "  âš ï¸  Invalid SMILES: 16 compounds\n",
      "\n",
      "  MW distribution of failed compounds:\n",
      "    â€¢ Mean: 1400.6 Da\n",
      "    â€¢ Min: 59.1 Da\n",
      "    â€¢ Max: 2430.9 Da\n",
      "\n",
      "================================================================================\n",
      "CHEMICAL FILTER 2: Covalent Motifs (â‰¤1)\n",
      "================================================================================\n",
      "Checking 20 covalent SMARTS patterns...\n",
      "  âœ“ Successfully compiled 20 SMARTS patterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:50:59] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:59] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:59] restricted\n",
      "[19:50:59] ^\n",
      "[19:50:59] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:59] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:59] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:59] restricted\n",
      "[19:50:59] ^\n",
      "[19:50:59] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:50:59] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:50:59] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:50:59] restricted\n",
      "[19:50:59] ^\n",
      "[19:50:59] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:02] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:02] restricted\n",
      "[19:51:02] ^\n",
      "[19:51:02] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Passed: 13,131 compounds\n",
      "  âœ— Failed (>1 motifs): 596 compounds\n",
      "\n",
      "  Distribution of failed compounds:\n",
      "    â€¢ Mean motifs: 2.2\n",
      "    â€¢ Max motifs: 4\n",
      "\n",
      "================================================================================\n",
      "CHEMICAL FILTER 3: NIBR Structure Flags (â‰¤9)\n",
      "================================================================================\n",
      "Using official NIBR filter catalog (Schuffenhauer et al. 2020)\n",
      "  âœ“ Catalog contains 444 filter patterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:51:04] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:04] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:04] restricted\n",
      "[19:51:04] ^\n",
      "[19:51:04] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:04] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:04] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:04] restricted\n",
      "[19:51:04] ^\n",
      "[19:51:04] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:06] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:06] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:06] restricted\n",
      "[19:51:06] ^\n",
      "[19:51:06] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:38] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:38] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:38] restricted\n",
      "[19:51:38] ^\n",
      "[19:51:38] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:38] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:38] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:38] restricted\n",
      "[19:51:38] ^\n",
      "[19:51:38] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:38] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:38] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:38] restricted\n",
      "[19:51:38] ^\n",
      "[19:51:38] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:39] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:39] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:39] restricted\n",
      "[19:51:39] ^\n",
      "[19:51:39] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:40] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:40] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:40] restricted\n",
      "[19:51:40] ^\n",
      "[19:51:40] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:40] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:40] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:40] restricted\n",
      "[19:51:40] ^\n",
      "[19:51:40] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:40] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:40] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:40] restricted\n",
      "[19:51:40] ^\n",
      "[19:51:40] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:41] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:41] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:41] restricted\n",
      "[19:51:41] ^\n",
      "[19:51:41] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:41] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:41] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:41] restricted\n",
      "[19:51:41] ^\n",
      "[19:51:41] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:42] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:42] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:42] restricted\n",
      "[19:51:42] ^\n",
      "[19:51:42] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:42] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:42] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:42] restricted\n",
      "[19:51:42] ^\n",
      "[19:51:42] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:42] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:42] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:42] restricted\n",
      "[19:51:42] ^\n",
      "[19:51:42] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:51:42] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:51:42] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:51:42] restricted\n",
      "[19:51:42] ^\n",
      "[19:51:42] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Passed: 12,380 compounds\n",
      "  âœ— Failed (>9 flags): 1,944 compounds\n",
      "\n",
      "  Flag distribution (all compounds):\n",
      "    â€¢ Mean flags: 2.32\n",
      "    â€¢ Median flags: 0\n",
      "    â€¢ Max flags: 10\n",
      "\n",
      "  Flag count histogram:\n",
      "    â€¢ 0 flags: 5,822 compounds\n",
      "    â€¢ 1 flags: 1,048 compounds\n",
      "    â€¢ 2 flags: 111 compounds\n",
      "    â€¢ 3 flags: 12 compounds\n",
      "    â€¢ 10 flags: 1,944 compounds\n",
      "\n",
      "  Failed compounds statistics:\n",
      "    â€¢ Mean flags: 10.00\n",
      "    â€¢ Max flags: 10\n",
      "\n",
      "================================================================================\n",
      "CHEMICAL FILTER 4: BRENK Criteria\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:52:05] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:05] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:05] restricted\n",
      "[19:52:05] ^\n",
      "[19:52:05] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:05] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:05] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:05] restricted\n",
      "[19:52:05] ^\n",
      "[19:52:05] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:05] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:05] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:05] restricted\n",
      "[19:52:05] ^\n",
      "[19:52:05] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n",
      "[19:52:11] SMILES Parse Error: syntax error while parsing: restricted\n",
      "[19:52:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[19:52:11] restricted\n",
      "[19:52:11] ^\n",
      "[19:52:11] SMILES Parse Error: Failed parsing SMILES 'restricted' for input: 'restricted'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Passed: 9,843 compounds\n",
      "  âœ— Failed (BRENK violations): 5,386 compounds\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š CHEMICAL FILTER SUMMARY\n",
      "================================================================================\n",
      "  Initial compounds: 18,187\n",
      "  Passed Filter 1 (MW): 13,429\n",
      "  Passed Filter 2 (Covalent): 13,131\n",
      "  Passed Filter 3 (NIBR): 12,380\n",
      "  Passed Filter 4 (BRENK): 9,843\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  âœ… Passed ALL filters: 9,434\n",
      "  âŒ Removed: 8,753\n",
      "  Retention rate: 51.9%\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š FILTERING TRAINING DATA\n",
      "================================================================================\n",
      "  Compounds in training data: 13,823\n",
      "  Compounds passed filters: 9,434\n",
      "  Compounds to remove: 4,389\n",
      "  Removing 276,536 samples from 4,389 compounds...\n",
      "\n",
      "================================================================================\n",
      "âœ… FILTERING COMPLETE\n",
      "================================================================================\n",
      "  Before chemical filters:\n",
      "    â€¢ Samples: 583,491\n",
      "    â€¢ Compounds: 13,823\n",
      "  After chemical filters:\n",
      "    â€¢ Samples: 306,955 (52.6%)\n",
      "    â€¢ Compounds: 9,434 (68.2%)\n",
      "    â€¢ Cell lines: 57\n",
      "  Removed:\n",
      "    â€¢ Samples: 276,536\n",
      "    â€¢ Compounds: 4,389\n",
      "\n",
      "ğŸ“Š Comparison with paper (SI page 2):\n",
      "  Paper: 425,242 obs, 9,597 compounds, 52 cells\n",
      "  Ours:  306,955 obs, 9,434 compounds, 57 cells\n",
      "  Match rate:\n",
      "    â€¢ Samples: 72.2%\n",
      "    â€¢ Compounds: 98.3%\n",
      "    â€¢ Cell lines: 109.6%\n",
      "\n",
      "ğŸ’¾ Saving filtered data to: E:\\ç§‘ç ”\\Models\\drugreflector\\processed_data\\training_data_lincs2020_chemfiltered_1201.pkl\n",
      "   âœ“ Saved successfully! (1283.1 MB)\n",
      "\n",
      "================================================================================\n",
      "âœ… CHEMICAL FILTERING COMPLETE!\n",
      "================================================================================\n",
      "ğŸ“ Final output: E:\\ç§‘ç ”\\Models\\drugreflector\\processed_data\\training_data_lincs2020_chemfiltered_1201.pkl\n",
      "ğŸ¯ Ready for training!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LINCS 2020 Chemical Filters\n",
    "æ ¹æ®DrugReflectorè®ºæ–‡SIç¬¬2é¡µå®ç°åŒ–å­¦è¿‡æ»¤\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# RDKit imports\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors, AllChem, FilterCatalog\n",
    "    from rdkit.Chem.FilterCatalog import FilterCatalogParams\n",
    "    RDKIT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  RDKit not installed. Install with: conda install -c conda-forge rdkit\")\n",
    "    RDKIT_AVAILABLE = False\n",
    "\n",
    "\n",
    "class ChemicalFilter:\n",
    "    \"\"\"\n",
    "    åŒ–å­¦è¿‡æ»¤å™¨ - æ ¹æ®DrugReflector SIå®ç°\n",
    "    \n",
    "    Filters applied (SI page 2):\n",
    "    1. Molecular weight: 60-1000 Da (inclusive)\n",
    "    2. No more than 1 covalent motif (SMARTS-defined)\n",
    "    3. No more than 9 NIBR structure flags\n",
    "    4. Pass BRENK criteria\n",
    "    5. Must not match 30 SMARTS patterns (not disclosed)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, compound_info_path: str, nibr_filter_csv: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–åŒ–å­¦è¿‡æ»¤å™¨\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "            compound_info_path: compoundinfo_beta.txtè·¯å¾„\n",
    "            nibr_filter_csv: NIBRè¿‡æ»¤å™¨CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰\n",
    "        \"\"\"\n",
    "        if not RDKIT_AVAILABLE:\n",
    "            raise ImportError(\"RDKit is required for chemical filtering\")\n",
    "        \n",
    "        self.compound_info_path = Path(compound_info_path)\n",
    "        self.compound_info = None\n",
    "        self.filtered_compounds = set()\n",
    "        \n",
    "        # åˆå§‹åŒ–BRENKè¿‡æ»¤å™¨\n",
    "        self.brenk_catalog = self._init_brenk_filter()\n",
    "        \n",
    "        # åˆå§‹åŒ–å…±ä»·åŸºå›¢SMARTS\n",
    "        self.covalent_smarts = self._init_covalent_smarts()\n",
    "        \n",
    "        # ğŸ”¥ æ–°å¢ï¼šåˆå§‹åŒ–NIBRè¿‡æ»¤å™¨ç›®å½•\n",
    "        self.nibr_catalog = self._init_nibr_filter(nibr_filter_csv)\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ğŸ§ª Chemical Filter Initialized\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Based on DrugReflector SI (page 2)\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    def _init_brenk_filter(self):\n",
    "        \"\"\"åˆå§‹åŒ–BRENKè¿‡æ»¤å™¨\"\"\"\n",
    "        params = FilterCatalogParams()\n",
    "        params.AddCatalog(FilterCatalogParams.FilterCatalogs.BRENK)\n",
    "        return FilterCatalog.FilterCatalog(params)\n",
    "    \n",
    "    def _init_covalent_smarts(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        å…±ä»·åŸºå›¢SMARTSæ¨¡å¼\n",
    "        \n",
    "        å‚è€ƒï¼š\n",
    "        - Backman et al. 2019 (ChEMBL structural alerts)\n",
    "        - Common covalent warheads in drug discovery\n",
    "        \"\"\"\n",
    "        return [\n",
    "            # Michael acceptors\n",
    "            'C=CC(=O)',  # Î±,Î²-unsaturated carbonyl\n",
    "            'C=CC(=O)N',  # acrylamide\n",
    "            'C=CC#N',  # acrylonitrile\n",
    "            \n",
    "            # Electrophilic carbonyls\n",
    "            '[C;!R](=O)Cl',  # acyl chloride\n",
    "            '[C;!R](=O)O[C;!R](=O)',  # anhydride\n",
    "            'C(=O)N=[N+]=[N-]',  # acyl azide\n",
    "            \n",
    "            # Epoxides and aziridines\n",
    "            'C1OC1',  # epoxide\n",
    "            'C1NC1',  # aziridine\n",
    "            \n",
    "            # Haloacetamides\n",
    "            'ClCC(=O)N',  # chloroacetamide\n",
    "            'BrCC(=O)N',  # bromoacetamide\n",
    "            \n",
    "            # Aldehydes (reactive)\n",
    "            '[CH;!R]=O',  # aldehyde\n",
    "            \n",
    "            # Isocyanates/isothiocyanates\n",
    "            'N=C=O',  # isocyanate\n",
    "            'N=C=S',  # isothiocyanate\n",
    "            \n",
    "            # Sulfonyl halides\n",
    "            'S(=O)(=O)Cl',  # sulfonyl chloride\n",
    "            'S(=O)(=O)F',  # sulfonyl fluoride\n",
    "            \n",
    "            # Nitriles (activated)\n",
    "            '[C;!R]#N',  # nitrile (non-aromatic)\n",
    "            \n",
    "            # Peroxides\n",
    "            'OO',  # peroxide\n",
    "            \n",
    "            # Beta-lactams (strained)\n",
    "            'C1(=O)NCC1',  # beta-lactam\n",
    "            \n",
    "            # Activated esters\n",
    "            'C(=O)OC(=O)',  # activated ester\n",
    "            \n",
    "            # Quinones\n",
    "            'C1=CC(=O)C=CC1=O',  # quinone\n",
    "        ]\n",
    "    \n",
    "    def _init_nibr_filter(self, csv_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–NIBRè¿‡æ»¤å™¨ç›®å½•ï¼ˆåŸºäºå®˜æ–¹444ä¸ªSMARTSï¼‰\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "            csv_path: NIBRè¿‡æ»¤å™¨CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰\n",
    "            \n",
    "        è¿”å›ï¼š\n",
    "            FilterCatalogå¯¹è±¡\n",
    "        \"\"\"\n",
    "        # ğŸ”¥ ç¡®å®šCSVæ–‡ä»¶è·¯å¾„\n",
    "        if csv_path is None:\n",
    "            # é»˜è®¤è·¯å¾„ï¼šå½“å‰è„šæœ¬ç›®å½•ä¸‹çš„chem_filteræ–‡ä»¶å¤¹\n",
    "            try:\n",
    "                # å°è¯•ä½¿ç”¨ __file__ï¼ˆåœ¨è„šæœ¬æ¨¡å¼ä¸‹ï¼‰\n",
    "                script_dir = Path(__file__).parent\n",
    "            except NameError:\n",
    "                # åœ¨äº¤äº’å¼ç¯å¢ƒä¸­ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•\n",
    "                script_dir = Path(os.getcwd())\n",
    "            csv_path = script_dir / \"chem_filter\" / \"SubstructureFilter_HitTriaging_wPubChemExamples.csv\"\n",
    "        else:\n",
    "            csv_path = Path(csv_path)\n",
    "        \n",
    "        if not csv_path.exists():\n",
    "            print(f\"âš ï¸  NIBR filter CSV not found: {csv_path}\")\n",
    "            print(f\"   Using fallback: empty NIBR catalog\")\n",
    "            return FilterCatalog.FilterCatalog()\n",
    "        \n",
    "        print(f\"ğŸ“– Loading NIBR filters from: {csv_path.name}\")\n",
    "        \n",
    "        # è¯»å–CSVå¹¶æ„å»ºFilterCatalog\n",
    "        try:\n",
    "            nibr_df = pd.read_csv(csv_path)\n",
    "            print(f\"   âœ“ Loaded {len(nibr_df)} NIBR filter patterns\")\n",
    "            \n",
    "            nibr_catalog = FilterCatalog.FilterCatalog()\n",
    "            \n",
    "            n_added = 0\n",
    "            for idx, row in nibr_df.iterrows():\n",
    "                try:\n",
    "                    # æå–å‚æ•°\n",
    "                    pattern_name = row['PATTERN_NAME']\n",
    "                    smarts = row['SMARTS']\n",
    "                    min_count = 1 if row['MIN_COUNT'] == 0 else int(row['MIN_COUNT'])\n",
    "                    severity = int(row['SEVERITY_SCORE'])\n",
    "                    covalent = int(row['COVALENT'])\n",
    "                    special_mol = int(row['SPECIAL_MOL'])\n",
    "                    set_name = row['SET_NAME']\n",
    "                    \n",
    "                    # æ„å»ºè¿‡æ»¤å™¨åç§°ï¼ˆä¸å®˜æ–¹ä»£ç ä¸€è‡´ï¼‰\n",
    "                    filter_name = f\"{pattern_name}_min({min_count})__{severity}__{covalent}__{special_mol}\"\n",
    "                    \n",
    "                    # åˆ›å»ºSMARTSåŒ¹é…å™¨\n",
    "                    matcher = FilterCatalog.SmartsMatcher(filter_name, smarts, min_count)\n",
    "                    \n",
    "                    # æ·»åŠ åˆ°ç›®å½•\n",
    "                    entry = FilterCatalog.FilterCatalogEntry(filter_name, matcher)\n",
    "                    entry.SetProp('Scope', set_name)\n",
    "                    entry.SetProp('Severity', str(severity))\n",
    "                    nibr_catalog.AddEntry(entry)\n",
    "                    \n",
    "                    n_added += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   âš ï¸  Failed to add filter {idx}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"   âœ“ Successfully added {n_added} NIBR filters to catalog\")\n",
    "            return nibr_catalog\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error loading NIBR filters: {e}\")\n",
    "            print(f\"   Using fallback: empty NIBR catalog\")\n",
    "            return FilterCatalog.FilterCatalog()\n",
    "    \n",
    "    def load_compound_info(self):\n",
    "        \"\"\"åŠ è½½åŒ–åˆç‰©ä¿¡æ¯\"\"\"\n",
    "        print(f\"ğŸ“– Loading compound information...\")\n",
    "        \n",
    "        if not self.compound_info_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Compound info file not found: {self.compound_info_path}\"\n",
    "            )\n",
    "        \n",
    "        self.compound_info = pd.read_csv(self.compound_info_path, sep='\\t')\n",
    "        \n",
    "        print(f\"   âœ“ Loaded {len(self.compound_info):,} compounds\")\n",
    "        print(f\"   âœ“ Columns: {list(self.compound_info.columns)}\")\n",
    "        \n",
    "        # æ£€æŸ¥SMILESåˆ—\n",
    "        smiles_col = None\n",
    "        for col in ['canonical_smiles', 'smiles', 'SMILES']:\n",
    "            if col in self.compound_info.columns:\n",
    "                smiles_col = col\n",
    "                break\n",
    "        \n",
    "        if smiles_col is None:\n",
    "            raise ValueError(\n",
    "                f\"SMILES column not found. Available columns: {list(self.compound_info.columns)}\"\n",
    "            )\n",
    "        \n",
    "        self.smiles_col = smiles_col\n",
    "        print(f\"   âœ“ Using '{smiles_col}' for molecular structures\")\n",
    "        \n",
    "        # æ£€æŸ¥æœ‰æ•ˆSMILESæ•°é‡\n",
    "        valid_smiles = self.compound_info[smiles_col].notna().sum()\n",
    "        print(f\"   âœ“ Compounds with valid SMILES: {valid_smiles:,}\")\n",
    "        \n",
    "        return self.compound_info\n",
    "    \n",
    "    def filter_1_molecular_weight(self, min_mw=60, max_mw=1000) -> set:\n",
    "        \"\"\"\n",
    "        Filter 1: åˆ†å­é‡è¿‡æ»¤ (60-1000 Da)\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "            min_mw: æœ€å°åˆ†å­é‡ï¼ˆé»˜è®¤60ï¼‰\n",
    "            max_mw: æœ€å¤§åˆ†å­é‡ï¼ˆé»˜è®¤1000ï¼‰\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            é€šè¿‡è¿‡æ»¤çš„åŒ–åˆç‰©IDé›†åˆ\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CHEMICAL FILTER 1: Molecular Weight ({min_mw}-{max_mw} Da)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        passed = set()\n",
    "        failed_mw = []\n",
    "        no_smiles = 0\n",
    "        invalid_smiles = 0\n",
    "        \n",
    "        for idx, row in self.compound_info.iterrows():\n",
    "            pert_id = row['pert_id']\n",
    "            smiles = row[self.smiles_col]\n",
    "            \n",
    "            # æ£€æŸ¥SMILESæ˜¯å¦å­˜åœ¨\n",
    "            if pd.isna(smiles) or smiles == '':\n",
    "                no_smiles += 1\n",
    "                continue\n",
    "            \n",
    "            # è§£æåˆ†å­\n",
    "            mol = Chem.MolFromSmiles(str(smiles))\n",
    "            if mol is None:\n",
    "                invalid_smiles += 1\n",
    "                continue\n",
    "            \n",
    "            # è®¡ç®—åˆ†å­é‡\n",
    "            mw = Descriptors.MolWt(mol)\n",
    "            \n",
    "            if min_mw <= mw <= max_mw:\n",
    "                passed.add(pert_id)\n",
    "            else:\n",
    "                failed_mw.append((pert_id, mw))\n",
    "        \n",
    "        print(f\"  âœ“ Passed: {len(passed):,} compounds\")\n",
    "        print(f\"  âœ— Failed (out of MW range): {len(failed_mw):,} compounds\")\n",
    "        print(f\"  âš ï¸  No SMILES: {no_smiles:,} compounds\")\n",
    "        print(f\"  âš ï¸  Invalid SMILES: {invalid_smiles:,} compounds\")\n",
    "        \n",
    "        if failed_mw:\n",
    "            failed_df = pd.DataFrame(failed_mw, columns=['pert_id', 'MW'])\n",
    "            print(f\"\\n  MW distribution of failed compounds:\")\n",
    "            print(f\"    â€¢ Mean: {failed_df['MW'].mean():.1f} Da\")\n",
    "            print(f\"    â€¢ Min: {failed_df['MW'].min():.1f} Da\")\n",
    "            print(f\"    â€¢ Max: {failed_df['MW'].max():.1f} Da\")\n",
    "        \n",
    "        return passed\n",
    "    \n",
    "    def filter_2_covalent_motifs(self, max_motifs=1) -> set:\n",
    "        \"\"\"\n",
    "        Filter 2: å…±ä»·åŸºå›¢è¿‡æ»¤ (â‰¤1ä¸ª)\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "            max_motifs: å…è®¸çš„æœ€å¤§å…±ä»·åŸºå›¢æ•°ï¼ˆé»˜è®¤1ï¼‰\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            é€šè¿‡è¿‡æ»¤çš„åŒ–åˆç‰©IDé›†åˆ\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CHEMICAL FILTER 2: Covalent Motifs (â‰¤{max_motifs})\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Checking {len(self.covalent_smarts)} covalent SMARTS patterns...\")\n",
    "        \n",
    "        passed = set()\n",
    "        failed_counts = []\n",
    "        \n",
    "        # é¢„ç¼–è¯‘SMARTS\n",
    "        smarts_mols = []\n",
    "        for smarts in self.covalent_smarts:\n",
    "            try:\n",
    "                smarts_mol = Chem.MolFromSmarts(smarts)\n",
    "                if smarts_mol:\n",
    "                    smarts_mols.append(smarts_mol)\n",
    "            except:\n",
    "                print(f\"  âš ï¸  Invalid SMARTS: {smarts}\")\n",
    "        \n",
    "        print(f\"  âœ“ Successfully compiled {len(smarts_mols)} SMARTS patterns\")\n",
    "        \n",
    "        for idx, row in self.compound_info.iterrows():\n",
    "            pert_id = row['pert_id']\n",
    "            smiles = row[self.smiles_col]\n",
    "            \n",
    "            if pd.isna(smiles):\n",
    "                continue\n",
    "            \n",
    "            mol = Chem.MolFromSmiles(str(smiles))\n",
    "            if mol is None:\n",
    "                continue\n",
    "            \n",
    "            # è®¡æ•°åŒ¹é…çš„å…±ä»·åŸºå›¢\n",
    "            motif_count = 0\n",
    "            for smarts_mol in smarts_mols:\n",
    "                if mol.HasSubstructMatch(smarts_mol):\n",
    "                    motif_count += 1\n",
    "            \n",
    "            if motif_count <= max_motifs:\n",
    "                passed.add(pert_id)\n",
    "            else:\n",
    "                failed_counts.append(motif_count)\n",
    "        \n",
    "        print(f\"  âœ“ Passed: {len(passed):,} compounds\")\n",
    "        print(f\"  âœ— Failed (>{max_motifs} motifs): {len(failed_counts):,} compounds\")\n",
    "        \n",
    "        if failed_counts:\n",
    "            print(f\"\\n  Distribution of failed compounds:\")\n",
    "            print(f\"    â€¢ Mean motifs: {np.mean(failed_counts):.1f}\")\n",
    "            print(f\"    â€¢ Max motifs: {max(failed_counts)}\")\n",
    "        \n",
    "        return passed\n",
    "    \n",
    "    def filter_3_nibr_flags(self, max_flags=9) -> set:\n",
    "        \"\"\"\n",
    "        Filter 3: NIBRç»“æ„æ ‡è®° (â‰¤9ä¸ª)\n",
    "        \n",
    "        ä½¿ç”¨å®˜æ–¹NIBR 444ä¸ªSMARTSè¿‡æ»¤å™¨\n",
    "        å‚è€ƒï¼šSchuffenhauer et al. 2020, J. Med. Chem.\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "            max_flags: å…è®¸çš„æœ€å¤§æ ‡è®°æ•°ï¼ˆé»˜è®¤9ï¼Œç¬¦åˆSIè¦æ±‚ï¼‰\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            é€šè¿‡è¿‡æ»¤çš„åŒ–åˆç‰©IDé›†åˆ\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CHEMICAL FILTER 3: NIBR Structure Flags (â‰¤{max_flags})\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Using official NIBR filter catalog (Schuffenhauer et al. 2020)\")\n",
    "        \n",
    "        if self.nibr_catalog is None or self.nibr_catalog.GetNumEntries() == 0:\n",
    "            print(f\"  âš ï¸  NIBR catalog is empty, skipping this filter\")\n",
    "            # è¿”å›æ‰€æœ‰åŒ–åˆç‰©ï¼ˆç›¸å½“äºä¸è¿‡æ»¤ï¼‰\n",
    "            return set(self.compound_info['pert_id'].values)\n",
    "        \n",
    "        print(f\"  âœ“ Catalog contains {self.nibr_catalog.GetNumEntries()} filter patterns\")\n",
    "        \n",
    "        passed = set()\n",
    "        failed_counts = []\n",
    "        flag_distribution = []\n",
    "        \n",
    "        for idx, row in self.compound_info.iterrows():\n",
    "            pert_id = row['pert_id']\n",
    "            smiles = row[self.smiles_col]\n",
    "            \n",
    "            if pd.isna(smiles):\n",
    "                continue\n",
    "            \n",
    "            mol = Chem.MolFromSmiles(str(smiles))\n",
    "            if mol is None:\n",
    "                continue\n",
    "            \n",
    "            # ğŸ”¥ ä½¿ç”¨FilterCatalogè·å–æ‰€æœ‰åŒ¹é…\n",
    "            matches = self.nibr_catalog.GetMatches(mol)\n",
    "            \n",
    "            if len(matches) == 0:\n",
    "                # æ²¡æœ‰åŒ¹é…ä»»ä½•flagï¼Œé€šè¿‡\n",
    "                flag_count = 0\n",
    "                passed.add(pert_id)\n",
    "            else:\n",
    "                # ğŸ”¥ è®¡ç®—flagæ•°é‡ï¼ˆå‚è€ƒå®˜æ–¹ä»£ç é€»è¾‘ï¼‰\n",
    "                # åªç»Ÿè®¡severity=1çš„FLAGï¼Œseverity=2çš„EXCLUDEå•ç‹¬å¤„ç†\n",
    "                severity_scores = []\n",
    "                for entry in matches:\n",
    "                    # æå–severityä¿¡æ¯\n",
    "                    desc = entry.GetDescription()\n",
    "                    # æ ¼å¼ï¼špattern_name_min(X)__severity__covalent__special_mol\n",
    "                    parts = desc.split('__')\n",
    "                    if len(parts) >= 2:\n",
    "                        severity = int(parts[1])\n",
    "                        severity_scores.append(severity)\n",
    "                \n",
    "                # ğŸ”¥ å…³é”®é€»è¾‘ï¼ˆä¸å®˜æ–¹ä»£ç ä¸€è‡´ï¼‰ï¼š\n",
    "                # å¦‚æœæœ‰severity=2ï¼ˆEXCLUDEï¼‰ï¼Œç›´æ¥æ ‡è®°ä¸º10ï¼ˆå¿…é¡»æ’é™¤ï¼‰\n",
    "                if 2 in severity_scores:\n",
    "                    flag_count = 10  # è¶…è¿‡é˜ˆå€¼ï¼Œå¿…é¡»æ’é™¤\n",
    "                else:\n",
    "                    # å¦åˆ™ï¼Œflag_count = severity=1çš„æ•°é‡\n",
    "                    flag_count = sum(1 for s in severity_scores if s == 1)\n",
    "                \n",
    "                flag_distribution.append(flag_count)\n",
    "                \n",
    "                if flag_count <= max_flags:\n",
    "                    passed.add(pert_id)\n",
    "                else:\n",
    "                    failed_counts.append(flag_count)\n",
    "        \n",
    "        print(f\"  âœ“ Passed: {len(passed):,} compounds\")\n",
    "        print(f\"  âœ— Failed (>{max_flags} flags): {len(failed_counts):,} compounds\")\n",
    "        \n",
    "        if flag_distribution:\n",
    "            print(f\"\\n  Flag distribution (all compounds):\")\n",
    "            print(f\"    â€¢ Mean flags: {np.mean(flag_distribution):.2f}\")\n",
    "            print(f\"    â€¢ Median flags: {np.median(flag_distribution):.0f}\")\n",
    "            print(f\"    â€¢ Max flags: {max(flag_distribution)}\")\n",
    "            \n",
    "            # ç»Ÿè®¡å„flagæ•°é‡çš„åˆ†å¸ƒ\n",
    "            from collections import Counter\n",
    "            flag_counts = Counter(flag_distribution)\n",
    "            print(f\"\\n  Flag count histogram:\")\n",
    "            for count in sorted(flag_counts.keys())[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ª\n",
    "                n_compounds = flag_counts[count]\n",
    "                print(f\"    â€¢ {count} flags: {n_compounds:,} compounds\")\n",
    "        \n",
    "        if failed_counts:\n",
    "            print(f\"\\n  Failed compounds statistics:\")\n",
    "            print(f\"    â€¢ Mean flags: {np.mean(failed_counts):.2f}\")\n",
    "            print(f\"    â€¢ Max flags: {max(failed_counts)}\")\n",
    "        \n",
    "        return passed\n",
    "    \n",
    "    def filter_4_brenk(self) -> set:\n",
    "        \"\"\"\n",
    "        Filter 4: BRENKè¿‡æ»¤å™¨\n",
    "        \n",
    "        BRENKè¿‡æ»¤å™¨è¯†åˆ«ä¸è‰¯çš„åŒ–å­¦åŸºå›¢å’Œååº”æ€§å®˜èƒ½å›¢\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            é€šè¿‡è¿‡æ»¤çš„åŒ–åˆç‰©IDé›†åˆ\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CHEMICAL FILTER 4: BRENK Criteria\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        passed = set()\n",
    "        failed = []\n",
    "        \n",
    "        for idx, row in self.compound_info.iterrows():\n",
    "            pert_id = row['pert_id']\n",
    "            smiles = row[self.smiles_col]\n",
    "            \n",
    "            if pd.isna(smiles):\n",
    "                continue\n",
    "            \n",
    "            mol = Chem.MolFromSmiles(str(smiles))\n",
    "            if mol is None:\n",
    "                continue\n",
    "            \n",
    "            # æ£€æŸ¥BRENKè¿‡æ»¤å™¨\n",
    "            matches = self.brenk_catalog.GetMatches(mol)\n",
    "            \n",
    "            if len(matches) == 0:\n",
    "                passed.add(pert_id)\n",
    "            else:\n",
    "                failed.append((pert_id, len(matches)))\n",
    "        \n",
    "        print(f\"  âœ“ Passed: {len(passed):,} compounds\")\n",
    "        print(f\"  âœ— Failed (BRENK violations): {len(failed):,} compounds\")\n",
    "        \n",
    "        return passed\n",
    "    \n",
    "    def apply_all_filters(self, target_compounds: Optional[set] = None) -> set:\n",
    "        \"\"\"\n",
    "        åº”ç”¨æ‰€æœ‰åŒ–å­¦è¿‡æ»¤å™¨\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            target_compounds: éœ€è¦è¿‡æ»¤çš„åŒ–åˆç‰©é›†åˆï¼ˆå¦‚æœæä¾›ï¼Œåˆ™åªè¿‡æ»¤è¿™äº›åŒ–åˆç‰©ï¼‰\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ§ª APPLYING ALL CHEMICAL FILTERS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        if self.compound_info is None:\n",
    "            self.load_compound_info()\n",
    "        \n",
    "        #  å¦‚æœæŒ‡å®šäº†ç›®æ ‡åŒ–åˆç‰©ï¼Œåªè¿‡æ»¤è¿™äº›\n",
    "        if target_compounds is not None:\n",
    "            print(f\"\\nâš ï¸  Filtering only {len(target_compounds):,} compounds present in training data\")\n",
    "            # ä¸´æ—¶ä¿å­˜åŸå§‹æ•°æ®\n",
    "            original_compound_info = self.compound_info.copy()\n",
    "            # åªä¿ç•™ç›®æ ‡åŒ–åˆç‰©\n",
    "            self.compound_info = self.compound_info[\n",
    "                self.compound_info['pert_id'].isin(target_compounds)\n",
    "            ]\n",
    "            print(f\"   Compounds to check: {len(self.compound_info):,}\")\n",
    "        \n",
    "        initial_compounds = len(self.compound_info)\n",
    "        print(f\"Initial compounds: {initial_compounds:,}\")\n",
    "        \n",
    "        # åº”ç”¨å„ä¸ªè¿‡æ»¤å™¨\n",
    "        passed_mw = self.filter_1_molecular_weight()\n",
    "        passed_covalent = self.filter_2_covalent_motifs()\n",
    "        passed_nibr = self.filter_3_nibr_flags()\n",
    "        passed_brenk = self.filter_4_brenk()\n",
    "        \n",
    "        # å–äº¤é›†\n",
    "        passed_all = passed_mw & passed_covalent & passed_nibr & passed_brenk\n",
    "        \n",
    "        # å¦‚æœæ˜¯é’ˆå¯¹ç›®æ ‡åŒ–åˆç‰©çš„è¿‡æ»¤ï¼Œæ¢å¤åŸå§‹æ•°æ®\n",
    "        if target_compounds is not None:\n",
    "            self.compound_info = original_compound_info\n",
    "        \n",
    "        # ç»Ÿè®¡\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ“Š CHEMICAL FILTER SUMMARY\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"  Initial compounds: {initial_compounds:,}\")\n",
    "        print(f\"  Passed Filter 1 (MW): {len(passed_mw):,}\")\n",
    "        print(f\"  Passed Filter 2 (Covalent): {len(passed_covalent):,}\")\n",
    "        print(f\"  Passed Filter 3 (NIBR): {len(passed_nibr):,}\")\n",
    "        print(f\"  Passed Filter 4 (BRENK): {len(passed_brenk):,}\")\n",
    "        print(f\"  {'â”€'*80}\")\n",
    "        print(f\"  âœ… Passed ALL filters: {len(passed_all):,}\")\n",
    "        print(f\"  âŒ Removed: {initial_compounds - len(passed_all):,}\")\n",
    "        print(f\"  Retention rate: {len(passed_all)/initial_compounds*100:.1f}%\")\n",
    "        \n",
    "        self.filtered_compounds = passed_all\n",
    "        return passed_all\n",
    "\n",
    "\n",
    "def apply_chemical_filters_to_training_data(\n",
    "    training_data_path: str,\n",
    "    compound_info_path: str,\n",
    "    output_path: Optional[str] = None,\n",
    "    nibr_filter_csv: Optional[str] = None\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    å¯¹è®­ç»ƒæ•°æ®åº”ç”¨åŒ–å­¦è¿‡æ»¤å™¨\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        training_data_path: è®­ç»ƒæ•°æ®pklæ–‡ä»¶è·¯å¾„\n",
    "        compound_info_path: compoundinfo_beta.txtè·¯å¾„\n",
    "        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰\n",
    "        nibr_filter_csv: NIBRè¿‡æ»¤å™¨CSVè·¯å¾„ï¼ˆå¯é€‰ï¼‰\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "        è¿‡æ»¤åçš„è®­ç»ƒæ•°æ®å­—å…¸\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ”¬ APPLYING CHEMICAL FILTERS TO TRAINING DATA\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # 1. åŠ è½½è®­ç»ƒæ•°æ®\n",
    "    print(f\"ğŸ“– Loading training data...\")\n",
    "    with open(training_data_path, 'rb') as f:\n",
    "        training_data = pickle.load(f)\n",
    "    \n",
    "    initial_samples = len(training_data['X'])\n",
    "    initial_compounds = len(training_data['compound_names'])\n",
    "    \n",
    "    print(f\"   âœ“ Loaded: {initial_samples:,} samples, {initial_compounds:,} compounds\")\n",
    "    \n",
    "    # è·å–è®­ç»ƒæ•°æ®ä¸­çš„åŒ–åˆç‰©\n",
    "    metadata = training_data['sample_meta']\n",
    "    training_compounds = set(metadata['pert_id'].unique())\n",
    "    print(f\"   âœ“ Training data contains: {len(training_compounds):,} unique compounds\")\n",
    "    \n",
    "    # 2. åº”ç”¨åŒ–å­¦è¿‡æ»¤å™¨ï¼ˆåªé’ˆå¯¹è®­ç»ƒæ•°æ®ä¸­çš„åŒ–åˆç‰©ï¼‰\n",
    "    filter_obj = ChemicalFilter(compound_info_path, nibr_filter_csv=nibr_filter_csv)  # ğŸ”¥ ä¼ é€’å‚æ•°\n",
    "    filter_obj.load_compound_info()\n",
    "    valid_compounds = filter_obj.apply_all_filters(target_compounds=training_compounds)\n",
    "    \n",
    "    # 3. è¿‡æ»¤è®­ç»ƒæ•°æ®\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ“Š FILTERING TRAINING DATA\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # valid_compoundsç°åœ¨æ˜¯training_compoundsçš„å­é›†\n",
    "    print(f\"  Compounds in training data: {len(training_compounds):,}\")\n",
    "    print(f\"  Compounds passed filters: {len(valid_compounds):,}\")\n",
    "    print(f\"  Compounds to remove: {len(training_compounds - valid_compounds):,}\")\n",
    "    \n",
    "    valid_mask = metadata['pert_id'].isin(valid_compounds)\n",
    "    \n",
    "    n_removed_samples = (~valid_mask).sum()\n",
    "    n_removed_compounds = len(training_compounds - valid_compounds)  # ä»è®­ç»ƒæ•°æ®ä¸­ç§»é™¤çš„\n",
    "\n",
    "    print(f\"  Removing {n_removed_samples:,} samples from {n_removed_compounds:,} compounds...\")\n",
    "    \n",
    "    # åˆ›å»ºæ–°çš„è®­ç»ƒæ•°æ®\n",
    "    filtered_data = {\n",
    "        'X': training_data['X'][valid_mask],\n",
    "        'y': None,  # éœ€è¦é‡æ–°ç¼–ç \n",
    "        'folds': training_data['folds'][valid_mask],\n",
    "        'sample_meta': metadata[valid_mask].reset_index(drop=True),\n",
    "        'metadata': metadata[valid_mask].reset_index(drop=True),\n",
    "        'gene_names': training_data['gene_names'],\n",
    "        'compound_names': None,  # éœ€è¦æ›´æ–°\n",
    "        'pert_to_idx': None  # éœ€è¦é‡æ–°æ„å»º\n",
    "    }\n",
    "    \n",
    "    # é‡æ–°æ„å»ºåŒ–åˆç‰©æ˜ å°„å’Œæ ‡ç­¾\n",
    "    new_compound_names = sorted(list(valid_compounds))\n",
    "    new_pert_to_idx = {pert: idx for idx, pert in enumerate(new_compound_names)}\n",
    "    new_labels = np.array([\n",
    "        new_pert_to_idx[pert] \n",
    "        for pert in filtered_data['sample_meta']['pert_id']\n",
    "    ], dtype=np.int32)\n",
    "    \n",
    "    filtered_data['compound_names'] = new_compound_names\n",
    "    filtered_data['pert_to_idx'] = new_pert_to_idx\n",
    "    filtered_data['y'] = new_labels\n",
    "    \n",
    "    # ç»Ÿè®¡\n",
    "    final_samples = len(filtered_data['X'])\n",
    "    final_compounds = len(new_compound_names)\n",
    "    \n",
    "    if 'cell_iname' in filtered_data['sample_meta'].columns:\n",
    "        final_cells = filtered_data['sample_meta']['cell_iname'].nunique()\n",
    "    else:\n",
    "        final_cells = 'Unknown'\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"âœ… FILTERING COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Before chemical filters:\")\n",
    "    print(f\"    â€¢ Samples: {initial_samples:,}\")\n",
    "    print(f\"    â€¢ Compounds: {initial_compounds:,}\")\n",
    "    print(f\"  After chemical filters:\")\n",
    "    print(f\"    â€¢ Samples: {final_samples:,} ({final_samples/initial_samples*100:.1f}%)\")\n",
    "    print(f\"    â€¢ Compounds: {final_compounds:,} ({final_compounds/initial_compounds*100:.1f}%)\")\n",
    "    print(f\"    â€¢ Cell lines: {final_cells}\")\n",
    "    print(f\"  Removed:\")\n",
    "    print(f\"    â€¢ Samples: {n_removed_samples:,}\")\n",
    "    print(f\"    â€¢ Compounds: {n_removed_compounds:,}\")\n",
    "    \n",
    "    # ä¸è®ºæ–‡å¯¹æ¯”\n",
    "    paper_samples = 425242\n",
    "    paper_compounds = 9597\n",
    "    paper_cells = 52\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Comparison with paper (SI page 2):\")\n",
    "    print(f\"  Paper: {paper_samples:,} obs, {paper_compounds:,} compounds, {paper_cells} cells\")\n",
    "    print(f\"  Ours:  {final_samples:,} obs, {final_compounds:,} compounds, {final_cells} cells\")\n",
    "    print(f\"  Match rate:\")\n",
    "    print(f\"    â€¢ Samples: {final_samples/paper_samples*100:.1f}%\")\n",
    "    print(f\"    â€¢ Compounds: {final_compounds/paper_compounds*100:.1f}%\")\n",
    "    if isinstance(final_cells, int):\n",
    "        print(f\"    â€¢ Cell lines: {final_cells/paper_cells*100:.1f}%\")\n",
    "    \n",
    "    # 4. ä¿å­˜\n",
    "    if output_path is None:\n",
    "        input_path = Path(training_data_path)\n",
    "        output_path = input_path.parent / f\"{input_path.stem}_chemfiltered.pkl\"\n",
    "    else:\n",
    "        output_path = Path(output_path)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ Saving filtered data to: {output_path}\")\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(filtered_data, f, protocol=4)\n",
    "    \n",
    "    file_size_mb = output_path.stat().st_size / (1024**2)\n",
    "    print(f\"   âœ“ Saved successfully! ({file_size_mb:.1f} MB)\")\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»ç¨‹åº - åº”ç”¨åŒ–å­¦è¿‡æ»¤å™¨\"\"\"\n",
    "    \n",
    "    # é…ç½®è·¯å¾„\n",
    "    data_dir = \"E:/ç§‘ç ”/Models/drugreflector/datasets/LINCS2020\"\n",
    "    processed_dir = \"E:/ç§‘ç ”/Models/drugreflector/processed_data\"\n",
    "    \n",
    "    training_data_path = Path(processed_dir) / \"training_data_lincs2020_optimized_1201.pkl\"\n",
    "    compound_info_path = Path(data_dir) / \"compoundinfo_beta.txt\"\n",
    "    output_path = Path(processed_dir) / \"training_data_lincs2020_chemfiltered_1201.pkl\"\n",
    "    \n",
    "    # NIBRè¿‡æ»¤å™¨CSVè·¯å¾„\n",
    "    # CSVæ–‡ä»¶åœ¨å½“å‰è„šæœ¬åŒçº§çš„chem_filteræ–‡ä»¶å¤¹ä¸‹\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ __file__ï¼ˆåœ¨è„šæœ¬æ¨¡å¼ä¸‹ï¼‰\n",
    "        script_dir = Path(__file__).parent\n",
    "    except NameError:\n",
    "        # åœ¨äº¤äº’å¼ç¯å¢ƒä¸­ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•\n",
    "        script_dir = Path(os.getcwd())\n",
    "    nibr_csv_path = script_dir / \"chem_filter\" / \"SubstructureFilter_HitTriaging_wPubChemExamples.csv\"\n",
    "    \n",
    "    # æ£€æŸ¥æ–‡ä»¶\n",
    "    if not training_data_path.exists():\n",
    "        print(f\"âŒ Training data not found: {training_data_path}\")\n",
    "        print(f\"   Please run data preprocessing first!\")\n",
    "        return\n",
    "    \n",
    "    if not compound_info_path.exists():\n",
    "        print(f\"âŒ Compound info not found: {compound_info_path}\")\n",
    "        return\n",
    "    \n",
    "    # æ£€æŸ¥NIBR CSVæ–‡ä»¶\n",
    "    if not nibr_csv_path.exists():\n",
    "        print(f\"âš ï¸  NIBR filter CSV not found: {nibr_csv_path}\")\n",
    "        print(f\"   Will use fallback NIBR filters (less accurate)\")\n",
    "        nibr_csv_path = None\n",
    "        \n",
    "    # åº”ç”¨è¿‡æ»¤å™¨\n",
    "    try:\n",
    "        filtered_data = apply_chemical_filters_to_training_data(\n",
    "            training_data_path=str(training_data_path),\n",
    "            compound_info_path=str(compound_info_path),\n",
    "            output_path=str(output_path)\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"âœ… CHEMICAL FILTERING COMPLETE!\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ğŸ“ Final output: {output_path}\")\n",
    "        print(f\"ğŸ¯ Ready for training!\")\n",
    "        \n",
    "        return filtered_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"âŒ ERROR\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"   Type: {type(e).__name__}\")\n",
    "        print(f\"   Message: {e}\")\n",
    "        \n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filtered_data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65a3dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 1, 0, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_processed = pd.read_pickle(\"E:/ç§‘ç ”/Models/drugreflector/processed_data/training_data_lincs2020_final.pkl\")\n",
    "\n",
    "data_processed['folds']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
